{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_epAAq6tS59"
      },
      "source": [
        "# Data Aquisition, Processing and Collation\n",
        "The following Jupyter Notebook collects the two datasets necessary for the MAPWAPS project application, namely: flux tower data and satellite data. It proceses the two datasets individually and then combines them to produce a single final dataset ready to be used in machine learning model training, valdation and testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDwY-VJ1tbkG"
      },
      "source": [
        "## Library and Function Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell imports several essential libraries and sets up functionalities in the Jupyter Notebook, ensuring that they are readily available for implementation and utilization later in the code"
      ],
      "metadata": {
        "id": "YM3i5VCF79ao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "ap77KRGhtXYu",
        "outputId": "ebb7ed9a-e2eb-4343-d5b9-4e970acb4c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.9 snuggs-1.4.7\n",
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=6Dfre95evLZpnudFDYH3rfI4Z1pPhZE_e15jbyKWCW0&tc=pQCXnjrCvRH19uKKs8JZT-w0D4DxqeMkc-I96S-A8-g&cc=DNxMD7-dR7MQuIR2kLbK3UEnEPDtAhCqwJUp3UkQ_xA\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AfJohXnWH83f37GC5i5EgIX5jbI6j0mxSDF5KG3K93DTQcoQ7-jQmBSzOLw\n",
            "\n",
            "Successfully saved authorization token.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio\n",
        "import ee\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geemap\n",
        "import re\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Authenticate with Earth Engine (requires user interaction)\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the Earth Engine Python API\n",
        "ee.Initialize()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ofb6MgatwJt"
      },
      "source": [
        "## Miscellaneous Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFpAcbzvt-GT"
      },
      "source": [
        "### save_df_to_drive\n",
        "Function that saves a Pandas DataFrame as a csv file to a Google Drive folder specified by a Google Drive file path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "VWdEqO_utw51",
        "outputId": "5c74a387-6f45-4926-e364-4fa6f3e490ab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def save_df_to_drive(df, file_path_in_google_drive):\n",
        "  \"\"\"\n",
        "  Function that saves a Pandas DataFrame as a csv file to a Google Drive folder specified by a google drive file path\n",
        "\n",
        "    parameter:  dataframe -> the Pandas DataFrame needing to be saved\n",
        "                file_path_in_drive -> Google Drive folder file path that will store the csv file\n",
        "    return:     void\n",
        "\n",
        "  \"\"\"\n",
        "  try:\n",
        "      # Ensure the destination directory exists\n",
        "      destination_dir = os.path.dirname(file_path_in_google_drive)\n",
        "      os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "      # Save the DataFrame to the specified file path in Google Drive\n",
        "      df.to_csv(file_path_in_google_drive, index=False)\n",
        "\n",
        "      print(f\"DataFrame saved to Google Drive at '{file_path_in_google_drive}'\")\n",
        "\n",
        "  except Exception as e:\n",
        "      print(\"An error occurred:\", str(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9EPLy1luvNU"
      },
      "source": [
        "## Flux Tower Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gjANH7hyJiR"
      },
      "source": [
        "### timestamp_separate\n",
        "Function that uses string handlng techniques to seperate the TIME_STAMP (YYYYMMDDHHMM) into TIME_STAMP_DATE (YYYYMMDD) and TIME_STAMP_TIME (HHMM) in order to isolate the date variable for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "qJdLHBhpyK7s",
        "outputId": "d4cddaaf-f954-4900-acd4-b4e7440bd333"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def timestamp_separate(df):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that uses string handling techniques to separate the flux tower variable TIME_STAMP (YYYYMMDDHHMM)\n",
        "  into TIME_STAMP_DATE (YYYYMMDD) and TIME_STAMP_TIME (HHMM) in order to isolate the date variable for later use\n",
        "\n",
        "    parameter:  df -> the Pandas DataFrame storing the original, unfiltered flux tower data\n",
        "    return:     df_time_seperated -> the Pandas DataFrame with manipulated date and time variables\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Manipulates the TIMESTAMP (both START and END) columns to split into DATE and TIME separately\n",
        "  # Convert TIMESTAMP columns to string\n",
        "  df['TIMESTAMP_START'] = df['TIMESTAMP_START'].astype(str)\n",
        "  df['TIMESTAMP_END'] = df['TIMESTAMP_END'].astype(str)\n",
        "\n",
        "  # Extract TIMESTAMP_DATE (YYMMDD) and TIMESTAMP_TIME (HHMM) (for both START and END) with string handling principles\n",
        "  df['TIMESTAMP_START_DATE'] = df['TIMESTAMP_START'].str[:8]\n",
        "  df['TIMESTAMP_START_TIME'] = df['TIMESTAMP_START'].str[8:]\n",
        "  df['TIMESTAMP_END_DATE'] = df['TIMESTAMP_END'].str[:8]\n",
        "  df['TIMESTAMP_END_TIME'] = df['TIMESTAMP_END'].str[8:]\n",
        "\n",
        "  # @ this stage the count variable should be 48 because the sampling rate is 30 minutes (24hrs x 2) and no entries have been removed\n",
        "  df['COUNT'] = df.groupby('TIMESTAMP_START_DATE')['TIMESTAMP_START_DATE'].transform('count')\n",
        "\n",
        "  # Specify TIMESTAMP columns order\n",
        "  start_columns = [\n",
        "      'TIMESTAMP_START', 'TIMESTAMP_START_DATE', 'TIMESTAMP_START_TIME',\n",
        "      'TIMESTAMP_END', 'TIMESTAMP_END_DATE', 'TIMESTAMP_END_TIME'\n",
        "  ]\n",
        "\n",
        "  # Define the df order with TIMESTAMP columns first and remaining columns in their original order\n",
        "  desired_order = start_columns + [col for col in df.columns if col not in start_columns]\n",
        "  df_time_seperated = df[desired_order]\n",
        "\n",
        "  return df_time_seperated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLoKcu4H6ihS"
      },
      "source": [
        "### check_LE\n",
        "Function that check if a dataset has an LE column and if not finds a LE column derivation and renames it LE for simplified use\n",
        "\n",
        "- Note: LE column derivation refers to a column that stores LE values but under a different column name (e.g. LE_1.1.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "g7wSNsGD6oqn",
        "outputId": "9bb33026-48b4-419a-ec85-3a164f3191ec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def check_LE(df):\n",
        "    \"\"\"\n",
        "    Function that check if a dataset has an LE column and if not finds a LE column derivation and renames it LE for simplified future use\n",
        "      Note: LE column derivation refers to a column that stores LE values but under a different column name (e.g. LE_1.1.1)\n",
        "\n",
        "    parameter:  df -> the Pandas DataFrame storing the original flux tower data (with LE or LE derived columns)\n",
        "    return:     df_with_LE -> the Pandas DataFrame with LE column name\n",
        "\n",
        "    \"\"\"\n",
        "    column_name = 'LE'                        # Column of interest is the Latent Heat Flux (LE)\n",
        "    df_with_LE = df\n",
        "\n",
        "    if not column_name in df.columns:         # The Pandas DataFrame does not have a column with name 'LE'\n",
        "      try:\n",
        "          # Find the first column that starts with 'LE'\n",
        "          LE_column = next(col for col in df.columns if col.startswith('LE'))\n",
        "\n",
        "          # Rename the column to 'LE'\n",
        "          df_with_LE = df.rename(columns={LE_column: 'LE'}, inplace=True)\n",
        "      except StopIteration:\n",
        "          # The Pandas DataFrame does not have a column name that starts with 'LE'\n",
        "          print(\"No column starts with 'LE'\")\n",
        "\n",
        "    return df_with_LE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE0HGzsfyaPi"
      },
      "source": [
        "### remove_null\n",
        "Function that removes any data entry/ row that has a null (-9999) Latent Heat Flux (LE) variable\n",
        "- there is commented out section of code that will remove any entry with a null value (LE variable or otherwise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "x81zBZbuyabK",
        "outputId": "07955f9f-d3a6-45eb-cece-7446c5838653"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def remove_null(df):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that removes any data entry/ row that has a null (-9999) Latent Heat Flux (LE) variable\n",
        "\n",
        "    parameter:  df -> the Pandas DataFrame with LE null (-9999) values\n",
        "    return:     df_without_LE_null_values -> the Pandas DataFrame with removed LE null (-9999) values\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # # ----------------------- use if all entries with null values need removal -----------------------\n",
        "  # # Removes any row with a null (-9999) value\n",
        "  # columns_to_check = df.columns[2:]\n",
        "  # void_filter_boolean = df[columns_to_check].apply(lambda x: (x != -9999).all(), axis=1) # creates a boolean mask to identify the presence of -9999 values\n",
        "  # df_without_null_values = df[void_filter_boolean] # applies mask to df\n",
        "  # # ------------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Removes any row with a LE column null (-9999) value\n",
        "  df = df[df['LE'] != -9999]\n",
        "  del df['COUNT']\n",
        "  df['COUNT'] = df.groupby('TIMESTAMP_START_DATE')['TIMESTAMP_START_DATE'].transform('count')     # Counts the number of entries per date\n",
        "  df_without_LE_null_values = df\n",
        "\n",
        "  return df_without_LE_null_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNG6_T7uyjfO"
      },
      "source": [
        "### group_df\n",
        "Function that will group a dataframe by the date and add up each of its other columns - this is because we want to deal with daily ET estimates.\n",
        "- It will also filter the dataframe to obtain only the neccessary variables: Date, LE, COUNT\n",
        "- If the COUNT variable is not 2304 (48 x 48) then that row is removed because it signals an 'incomplete' dataset in that due to null value removals, there is not a full days worth of collected data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "oDHiJqd0yjpY",
        "outputId": "0dec8e81-450a-46f5-c8a9-3456131c01b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def group_df(df):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that groups a Pandas DataFrame by the date variable and adds up the other columns\n",
        "\n",
        "    parameter:  df -> the Pandas DataFrame with half hourly data readings (i.e. 48 readings per day - unless null values have been removed)\n",
        "    return:     df_grouped -> the Pandas DataFrame with grouped entries/ rows and daily LE values\n",
        "                              (only entries with a full day of recordings will be included - i.e. the daily count of 2304 = 48 x 48)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  df_simplified = df[['TIMESTAMP_START_DATE','LE','COUNT']]         # Creates a new filtered Pandad DataFrame with only the important columns\n",
        "  # df_simplified.head()           # Uncomment to ensure proper dataframe simplification\n",
        "\n",
        "  # Group by 'TIMESTAMP_START_DATE' and sum the 'LE' and 'COUNT' columns\n",
        "  df_grouped = df_simplified.groupby('TIMESTAMP_START_DATE').agg({'LE': 'sum', 'COUNT': 'sum'}).reset_index()\n",
        "  df_grouped.rename(columns={'TIMESTAMP_START_DATE': 'DATE', 'LE': 'DAILY LE', 'COUNT': 'DAILY COUNT'}, inplace=True) # Rename the columns\n",
        "\n",
        "  # Drop all 'incomplete' entries (those that do not have a days worth of data)\n",
        "  df_grouped = df_grouped[df_grouped['DAILY COUNT'] == 2304]\n",
        "\n",
        "  return df_grouped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cju7kPvyUGd"
      },
      "source": [
        "## Landsat Satellite Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOa3asdjuvgl"
      },
      "source": [
        "### Image Bands and Plant Indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sg9DvmEuvsh"
      },
      "source": [
        "#### get_landsat_bands\n",
        "Function that extracts the multispectral bands from a Landsat 8 satellite image of a co-ordinate specified location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "_vY4T9EOvPT0",
        "outputId": "dac2a69d-e31c-4a83-978d-ab654f9ff3ab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_landsat_bands(image_id, latitude, longitude):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that extracts the multispectral bands from a Landsat 8 satellite image of a co-ordinate specified location\n",
        "\n",
        "    parameter:  image_id -> unique Landsat 8 image ID\n",
        "                latitude -> latitude co-ordinate of desired location\n",
        "                longitude -> longitude co-ordinate of desired location\n",
        "    return:     band_dict -> dictionary of multispectral band values for a specified location with labels B1 - B11\n",
        "\n",
        "  \"\"\"\n",
        "  try:\n",
        "      # Load the Landsat image by its ID\n",
        "      landsat_image = ee.Image(image_id)\n",
        "\n",
        "      # Define a point geometry for the specified latitude and longitude\n",
        "      point_geometry = ee.Geometry.Point([longitude, latitude])\n",
        "\n",
        "      # Use the .sample() method to extract pixel values at the specified geometry\n",
        "      # This will create a feature collection containing the pixel values\n",
        "      pixel_values = landsat_image.sample(point_geometry, 30)  # 30 meters scale for Landsat\n",
        "\n",
        "      # Initialize an empty dictionary to store the band values\n",
        "      band_dict = {}\n",
        "\n",
        "      # Extract band values from the feature collection and add them to the dictionary\n",
        "      for band_name in landsat_image.bandNames().getInfo():\n",
        "          band_value = pixel_values.first().get(band_name).getInfo()\n",
        "          band_dict[band_name] = band_value\n",
        "\n",
        "      return band_dict\n",
        "\n",
        "  except ee.EEException as e:\n",
        "      return {\"error\": \"An Earth Engine exception occurred: \" + str(e)}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW7zVy6qvXFe"
      },
      "source": [
        "#### get_cloud_cover\n",
        "Function that extracts the cloud cover percentage from a satellite image specified by a Landsat 8 image ID\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "K21I80dlvZY4",
        "outputId": "c892b292-e373-41b9-e901-9907bbac7a05"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_cloud_cover(image_id):\n",
        "  \"\"\"\n",
        "  Function that extracts the cloud cover percentage from a satellite image specified by a Landsat 8 image ID\n",
        "\n",
        "    parameter:  image_id -> Landsat 8 image ID\n",
        "    return:     cloud_cover_rounded -> percentage cloud cover rounded to 3 decimal points\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Load the Landsat image using the provided image_id\n",
        "  image = ee.Image(image_id)\n",
        "\n",
        "  # Get the cloud cover property\n",
        "  cloud_cover = image.get('CLOUD_COVER').getInfo()\n",
        "\n",
        "  # Round the cloud cover percentage to 3 decimal places\n",
        "  cloud_cover_rounded = round(cloud_cover, 3)\n",
        "\n",
        "  return cloud_cover_rounded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDxovsU2vg_7"
      },
      "source": [
        "#### calculate_ndvi\n",
        "Function that calculates the Normalised Diffference Vegetation Index (NDVI)\n",
        "\n",
        "$ NDVI = \\frac{NIR - Red}{NIR + Red} \\in (-1, 1)$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "2SxpBwXSvmrb",
        "outputId": "ecf5f5eb-1f1c-4d56-9f4f-c83562ee56b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def calculate_ndvi(band_dict):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that calculates the Normalised Diffference Vegetation Index (NDVI) from the multispectral bands of a satellite image\n",
        "\n",
        "    parameter:  band_dict -> dictionary of multispectral band values\n",
        "    return:     ndvi -> Normalised Diffference Vegetation Index (NDVI) value\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "      # Extract the values for the NIR (Near Infrared) and Red bands from the dictionary\n",
        "      nir = band_dict['B5']  # Assuming 'B5' is the NIR band\n",
        "      red = band_dict['B4']  # Assuming 'B4' is the Red band\n",
        "\n",
        "      # Calculate NDVI\n",
        "      ndvi = (nir - red) / (nir + red)\n",
        "\n",
        "      return ndvi\n",
        "\n",
        "  except KeyError:\n",
        "      return {\"error\": \"Required bands (NIR and Red) not found in the band dictionary.\"}\n",
        "  except ZeroDivisionError:\n",
        "      return {\"error\": \"Division by zero error. Check if NIR + Red is zero.\"}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOQ7ctGsvsuM"
      },
      "source": [
        "#### calculate_vari\n",
        "Function that calculates the Visible Atmospherically Resistant Index (VARI)\n",
        "\n",
        "$VARI = \\frac{Green - Red}{Green + Red - Blue}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "2BowJQf9vzP1",
        "outputId": "7ae437eb-d1b5-4608-fa38-23a27f133b55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def calculate_vari(band_dict):\n",
        "  \"\"\"\n",
        "  Function that calculates the Visible Atmospherically Resistant Index (VARI) from the multispectral bands of a satellite image\n",
        "\n",
        "    parameter:  band_dict -> dictionary of multispectral band values\n",
        "    return:     vari -> Visible Atmospherically Resistant Index (VARI) value\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "      # Extract the values for the Blue, Red, and Green bands from the dictionary\n",
        "      blue = band_dict['B2']  # Assuming 'B2' is the Blue band\n",
        "      red = band_dict['B4']   # Assuming 'B4' is the Red band\n",
        "      green = band_dict['B3'] # Assuming 'B3' is the Green band\n",
        "\n",
        "      # Calculate VARI\n",
        "      vari = (green - red) / (green + red - blue)\n",
        "\n",
        "      return vari\n",
        "\n",
        "  except KeyError:\n",
        "      return {\"error\": \"Required bands (Blue, Red, and Green) not found in the band dictionary.\"}\n",
        "  except ZeroDivisionError:\n",
        "      return {\"error\": \"Division by zero error. Check if Green + Red - Blue is zero.\"}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDGSPKHHv6_8"
      },
      "source": [
        "#### calculate_savi\n",
        "Function that calculates the Soil Adjusted Vegetation Index (SAVI)\n",
        "\n",
        "$ SAVI = \\frac{(1 + L) \\cdot (NIR - Red)}{NIR + Red + L} \\in (-1.0, 1.0)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "UNjmQl6Rv-Tn",
        "outputId": "053fc71b-dc0d-4465-e2aa-5cc72102ecf7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def calculate_savi(band_dict):\n",
        "  \"\"\"\n",
        "  Function that calculates the Soil Adjusted Vegetation Index (SAVI) from the multispectral bands of a satellite image\n",
        "\n",
        "    parameter:  band_dict -> dictionary of multispectral band values\n",
        "    return:     savi -> Soil Adjusted Vegetation Index (SAVI) value\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "      # Extract the values for the NIR (Near Infrared) and Red bands from the dictionary\n",
        "      nir = band_dict['B5']  # Assuming 'B5' is the NIR band\n",
        "      red = band_dict['B4']  # Assuming 'B4' is the Red band\n",
        "\n",
        "      # Set the soil adjustment factor (L)\n",
        "      L = 0.5\n",
        "\n",
        "      # Calculate SAVI\n",
        "      savi = ((1 + L) * (nir - red)) / (nir + red + L)\n",
        "\n",
        "      return savi\n",
        "\n",
        "  except KeyError:\n",
        "      return {\"error\": \"Required bands (NIR and Red) not found in the band dictionary.\"}\n",
        "  except ZeroDivisionError:\n",
        "      return {\"error\": \"Division by zero error. Check if NIR + Red + L is zero.\"}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZVAIMBQwDm6"
      },
      "source": [
        "#### calculate_ndwi\n",
        "\n",
        "Function that calculates the Normalised Diffference Water Index (NDWI)\n",
        "\n",
        "$ NDWI = \\frac{Green - NIR}{Green + NIR} \\in (-1, 1)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "wNYzzUbrwKd2",
        "outputId": "f2aa2612-19d5-4d0e-d3ba-59a58c39c24b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def calculate_ndwi(band_dict):\n",
        "  \"\"\"\n",
        "  Function that calculates the Normalised Diffference Water Index (NDWI) from the multispectral bands of a satellite image\n",
        "\n",
        "    parameter:  band_dict -> dictionary of multispectral band values\n",
        "    return:     ndwi -> Normalised Diffference Water Index (NDWI) value\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "      # Extract the values for the Green and NIR bands from the dictionary\n",
        "      green = band_dict['B3']  # Assuming 'B3' is the Green band\n",
        "      nir = band_dict['B5']    # Assuming 'B5' is the NIR band\n",
        "\n",
        "      # Calculate NDWI\n",
        "      ndwi = (green - nir) / (green + nir)\n",
        "\n",
        "      return ndwi\n",
        "\n",
        "  except KeyError:\n",
        "      return {\"error\": \"Required bands (Green and NIR) not found in the band dictionary.\"}\n",
        "  except ZeroDivisionError:\n",
        "      return {\"error\": \"Division by zero error. Check if Green + NIR is zero.\"}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4X_hLrCwQcD"
      },
      "source": [
        "#### calculate_evi\n",
        "\n",
        "Function that calculates the Enhanced Vegetation Index (EVI)\n",
        "\n",
        "$ EVI =  \\frac{2.5 \\cdot (NIR - Red)}{NIR + 6 \\cdot Red - 7.5 \\cdot Blue + 1} $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "uZhT5q6AwUGU",
        "outputId": "5912e036-d026-4c76-9f9d-21c9929ec81d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def calculate_evi(band_dict):\n",
        "  \"\"\"\n",
        "  Function that calculates the Enhanced Vegetation Index (EVI) from the multispectral bands of a satellite image\n",
        "\n",
        "    parameter:  band_dict -> dictionary of multispectral band values\n",
        "    return:     evi -> Enhanced Vegetation Index (EVI) value\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "      # Extract the values for the Blue, Red, and NIR bands from the dictionary\n",
        "      blue = band_dict['B2']  # Assuming 'B2' is the Blue band\n",
        "      red = band_dict['B4']   # Assuming 'B4' is the Red band\n",
        "      nir = band_dict['B5']   # Assuming 'B5' is the NIR band\n",
        "\n",
        "      # Parameters for EVI calculation\n",
        "      G = 2.5\n",
        "      C1 = 6.0\n",
        "      C2 = 7.5\n",
        "      L = 1.0  # Can be adjusted for different regions\n",
        "\n",
        "      # Calculate EVI\n",
        "      evi = G * (nir - red) / (nir + (C1 * red) - (C2 * blue) + L)\n",
        "\n",
        "      return evi\n",
        "\n",
        "  except KeyError:\n",
        "      return {\"error\": \"Required bands (Blue, Red, and NIR) not found in the band dictionary.\"}\n",
        "  except ZeroDivisionError:\n",
        "      return {\"error\": \"Division by zero error. Check if NIR + C2*Red + L is zero.\"}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8yPWOw7wYaC"
      },
      "source": [
        "### Image Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4BAySrRw8Jj"
      },
      "source": [
        "#### get_collection_landsat_image_ids\n",
        "Function that extracts a list of Landsat 8 image IDs of a co-ordinate specified location within a date range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "lnSr1b2tw8ZZ",
        "outputId": "c5035238-464b-4c79-8f62-a9acf0d77e91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_collection_landsat_image_ids(start_date, end_date, latitude, longitude):\n",
        "  \"\"\"\n",
        "  Function that extracts a list of Landsat 8 image IDs of a co-ordinate specified location within a date range\n",
        "\n",
        "    parameter:  start_date -> start date of the date range\n",
        "                end_date -> end date of the date range\n",
        "                latitude -> latitude co-ordinate of desired location\n",
        "                longitude -> longitude co-ordinate of desired location\n",
        "    return:     image_id_list -> list of Landsat 8 image IDs\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a point of interest (POI) as a geometry\n",
        "  poi = ee.Geometry.Point(longitude, latitude)\n",
        "\n",
        "  # Create an image collection for Landsat imagery\n",
        "  landsat_collection = ee.ImageCollection('LANDSAT/LC08/C01/T1_TOA') \\\n",
        "        .filterBounds(poi) \\\n",
        "        .filterDate(ee.Date.parse('YYYYMMdd', start_date), ee.Date.parse('YYYYMMdd', end_date))\n",
        "\n",
        "  # Get a list of image IDs in the collection\n",
        "  image_ids = landsat_collection.aggregate_array('system:id')\n",
        "\n",
        "  # Get the image IDs as a Python list\n",
        "  image_id_list = image_ids.getInfo()\n",
        "\n",
        "  return image_id_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u57QZ1lGw8oa"
      },
      "source": [
        "#### create_df_from_image_ids\n",
        " Function that creates a Pandas Dataframe from the Landsat 8 image collection: Image ID, Date, Co-ordinates, Band Values, Cloud Cover Percentage and Plant Indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "LLLQEYWdw8y2",
        "outputId": "1dd72c58-9082-496e-ddf8-2870f19060ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def create_df_from_image_ids(image_ids, latitude, longitude):\n",
        "  \"\"\"\n",
        "  Function that creates a Pandas Dataframe from the Landsat 8 image collection: Image ID, Date, Co-ordinates, Band Values, Cloud Cover Percentage and Plant Indices.\n",
        "\n",
        "    parameter:  image_ids -> list of Landsat 8 image IDs\n",
        "                latitude -> latitude co-ordinate of desired location\n",
        "                longitude -> longitude co-ordinate of desired location\n",
        "    return:     df -> Pandas DataFrame of satellite data information for each Landsat 8 image ID\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  data = []\n",
        "\n",
        "  for image_id in image_ids:\n",
        "      # Extract date from the image ID and remove hyphens\n",
        "      date_str = image_id.split('_')[3]\n",
        "      date = ''.join(date_str.split('-'))\n",
        "\n",
        "      # Get Landsat band values for the current image\n",
        "      band_values = get_landsat_bands(image_id, latitude, longitude)\n",
        "\n",
        "      cloud = get_cloud_cover(image_id)\n",
        "\n",
        "      # Calculate Plant Indices (NDVI, EVI, SAVI, NDWI, EVI) for the current image\n",
        "      ndvi = calculate_ndvi(band_values)\n",
        "      evi = calculate_evi(band_values)\n",
        "      savi = calculate_savi(band_values)\n",
        "      ndwi = calculate_ndwi(band_values)\n",
        "      vari = calculate_vari(band_values)\n",
        "\n",
        "      # Append the data as a dictionary to the list, including band values\n",
        "      data.append({'Landsat Image ID': image_id, 'Date': date, 'Latitude': latitude, 'Longitude': longitude, **band_values, 'Cloud Cover': cloud, 'NDVI': ndvi, 'EVI': evi, 'SAVI': savi, 'VARI': vari, 'NDWI': ndwi})\n",
        "\n",
        "  # Create the Pandas DataFrame using pandas.concat\n",
        "  df = pd.concat([pd.DataFrame([d]) for d in data], ignore_index=True)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IjQsNGUuwCy"
      },
      "source": [
        "## Ameriflux Application\n",
        "\n",
        "Note: the code's commenting often refers to two attempts (where one will always be commented out and the other implemented). Attempt 1 refers to the spatially constricted 66 datasets and attempt 2 refers to the all inclusive 375 datasets. It is important that before running, each of the following cells are implementing the same attempt (i.e. all commented out or included sections agree on which attmept is being implemented)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F6Es3r6zHOh"
      },
      "source": [
        "### Ameriflux Site Overview Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "B0OPhbJAzM3g",
        "outputId": "28d93dcf-79ca-4380-9c3b-6c38653c985c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description Filtered.csv'\n"
          ]
        }
      ],
      "source": [
        "# Ameriflux allows you to download a CSV file summarising the flux tower sites whose data you have chosen to use and their characteristics.\n",
        "#     -   the importance of this is so link the flux tower site (Site ID) with its co-ordinate point\n",
        "\n",
        "# Specify the Google Drive file path of the AmeriFlux Site Overview Dataset\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "site_overview_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description.csv'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# site_overview_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description Extended.csv'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# Load the AmeriFlux Site Overview Dataset into a Pandas DataFrame\n",
        "df_site_overview = pd.read_csv(site_overview_file_path, delimiter=';')\n",
        "\n",
        "# df_site_overview.head()                               # Uncomment to ensure proper csv file upload\n",
        "\n",
        "# Filter the AmeriFlux Site Overview Dataset\n",
        "df_site_overview['Years of AmeriFlux BASE Data'] = df_site_overview['Years of AmeriFlux BASE Data'].astype(str)                               # Converts list to string\n",
        "df_site_overview['Start Year'] = df_site_overview['Years of AmeriFlux BASE Data'].apply(lambda x: min(map(int, x.strip('()').split(','))))    # Extracts the first year from the list\n",
        "df_site_overview['End Year'] = df_site_overview['Years of AmeriFlux BASE Data'].apply(lambda x: max(map(int, x.strip('()').split(','))))      # Extracts the last year from the list\n",
        "\n",
        "# df_site_overview.head()                               # Uncomment to ensure proper start and end year extraction\n",
        "\n",
        "important_columns = ['Site ID', 'Latitude (degrees)', 'Longitude (degrees)', 'Start Year', 'End Year']    # Specifies important columns (the rest will be discarded for simplicity)\n",
        "df_site_overview_filtered = df_site_overview[important_columns]                                           # Creates a new filtered Pandad DataFrame with only the important columns\n",
        "\n",
        "# Saves the filtered AmeriFlux Site Overview Dataset the a specified Google Drive file path\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "save_df_to_drive(df_site_overview_filtered, '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description Filtered.csv')\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# save_df_to_drive(df_site_overview_filtered, '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description Extended Filtered.csv')\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# df_site_overview_filtered.head()                      # Uncomment to view simplified/ filtered database containing the needed variables\n",
        "# print(df_site_overview_filtered.info())               # Uncomment to view the Pandas DataFrame's characteristics (# columns, # rows, variables, variable types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJpk4_0ruwKR"
      },
      "source": [
        "### Ameriflux Individual Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Individual Dataset Functions"
      ],
      "metadata": {
        "id": "Qfms_gxBO4E4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### get_date_range_and_coordinates\n",
        "Function that obtains the co-ordinates and operational date range of a flux tower from the AmeriFlux Site Overview dataset to be used as input parameters in extracting the landsat satellite image dataset"
      ],
      "metadata": {
        "id": "aDXXW1r7PCTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_date_range_and_coordinates(site_overview_df, file_name):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that obtains the co-ordinates and operational date range of a flux tower from the AmeriFlux Site Overview dataset\n",
        "    to be used as input parameters in extracting the landsat satellite image dataset\n",
        "\n",
        "    parameter:  site_overview_df -> overview Pandas DataFrame describing the Ameriflux flux towers and their characteristics\n",
        "                file_name -> file name of an individual Ameriflux flux tower dataset\n",
        "    return:     data_array -> array of an individual Ameriflux flux tower's characteristics (co-ordinates and date range)\n",
        "\n",
        "  \"\"\"\n",
        "  # Extract the Site ID from the flux tower dataset\n",
        "  pattern = r'AMF_(.*?)_BASE'                 # Define a regex pattern to match the desired substring - in this case the Site ID of the flux tower\n",
        "  match = re.search(pattern, file_name)       # Use re.search to find the match (i.e. the row in the overview table that refers to the name of the individual flux tower dataset)\n",
        "\n",
        "  site_id = match.group(1)\n",
        "  row_number = site_overview_df[site_overview_df['Site ID'] == site_id].index[0]      # Obtain the row number of the matched Site ID in the AmerFlux Site Overview dataset\n",
        "  longitude = site_overview_df.loc[row_number, 'Longitude (degrees)']                 # Extract the longitude from the specified row\n",
        "  latitude = site_overview_df.loc[row_number, 'Latitude (degrees)']                   # Extract the latitude from the specified row\n",
        "  start_year = site_overview_df.loc[row_number, 'Start Year']                         # Extract the start year from the specified row\n",
        "  end_year = site_overview_df.loc[row_number, 'End Year']                             # Extract the end year from the specified row\n",
        "\n",
        "  data_array = [latitude, longitude, start_year, end_year]              # Append extracted parameters to a list\n",
        "\n",
        "  return data_array\n",
        "\n",
        "site_overview_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description Filtered.csv'\n",
        "df_site_overview_filtered = pd.read_csv(site_overview_file_path)\n",
        "get_date_range_and_coordinates(df_site_overview_filtered, 'AMF_US-DS3_BASE_HH_1-5.csv')"
      ],
      "metadata": {
        "id": "8X18DYK8PAwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "da5170d7-ff17-4a7d-a7f6-ca4a1139cf20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[38.1235, -121.549, 2021, 2022]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### data_aquisition\n",
        "Function that creates and stores a filtered flux tower dataset and a generated Landsat 8 satellite dataset for each Ameriflux flux tower and saves them to specified Google Drive file paths"
      ],
      "metadata": {
        "id": "9BUk89Z7PNfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_aquisition(file_name):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that creates and stores a filtered flux tower dataset and a generated Landsat 8 satellite dataset for each Ameriflux flux tower and saves them to Google Drive folders\n",
        "\n",
        "    parameter:  file_name -> file name of an individual Ameriflux flux tower dataset\n",
        "    return:     void\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  csv_path = folder_path+\"/\"+file_name                            # Specify the Google Drive file path of the individual AmeriFlux flux tower Dataset using input paramter file_name\n",
        "  df = pd.read_csv(csv_path, delimiter=',', skiprows=2)           # Load the individual AmeriFlux flux tower Dataset into a Pandas DataFrame\n",
        "\n",
        "  # Filter the individual AmeriFlux flux tower dataset using pre-defined functions\n",
        "  df_time_seperated = timestamp_separate(df)                      # separate the timestamp variables of the Pandas DataFrame\n",
        "  df_with_LE = check_LE(df_time_seperated)                        # ensure the Pandas DataFrame has a LE column\n",
        "  df_without_LE_null_values = remove_null(df_with_LE)             # remove all null LE values from the Pandas DataFrame\n",
        "  df_grouped = group_df(df_without_LE_null_values)                # group the Pandas DataFrame by date to obtain daily entries\n",
        "\n",
        "\n",
        "  # Specify the Google Drive file path where the filtered individual AmeriFlux flux tower Dataset must be saved\n",
        "  # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "  flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered/'+file_name+' - Flux Data.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "  # flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered Extended/'+file_name+' - Flux Data Extended.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # Save the filtered individual AmeriFlux flux tower Dataset to the specified Google Drive file path\n",
        "  save_df_to_drive(df_grouped, flux_file_path)\n",
        "\n",
        "  # Generate the individual Landsat 8 satellite datasets using pre-defined functions\n",
        "  parameter_array = get_date_range_and_coordinates(df_site_overview_filtered, file_name)  # obtain the operation date range and co-ordinate specified location of the flux tower\n",
        "  latitude = parameter_array[0]                 # Extract the latitude\n",
        "  longitude = parameter_array[1]                # Extract the longitude\n",
        "  start_year = str(parameter_array[2])          # Extract the start year\n",
        "  end_year = str(parameter_array[3])            # Extract the end year\n",
        "\n",
        "  # Set the start date to the 1st of January [start year] and the end date to the 31st of December [end year]\n",
        "  start_date = start_year+'0101'\n",
        "  end_date = end_year+'1231'\n",
        "\n",
        "  # Check that the satellite can be extracted due to the operational limit of Landsat 8 satellite being post 2013\n",
        "  if int(end_year) < 2013:\n",
        "    print('Dataset cannot be extracted - outside of Landsat 8 range')\n",
        "  else:\n",
        "    landsat_ids = get_collection_landsat_image_ids(start_date, end_date, latitude, longitude)             # Create the Landsat image ID list\n",
        "\n",
        "    # This ensure code continuation in the case that the landsat_ids list is empty\n",
        "    try:\n",
        "      df_landsat = create_df_from_image_ids(landsat_ids, latitude, longitude)                             # Generate the individual Landsat 8 satellite dataset\n",
        "\n",
        "      # Specify the Google Drive file path where the filtered individual Landsat 8 satellite Dataset must be saved\n",
        "      # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "      landsat_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/First/'+file_name+' - Landsat Data.csv'\n",
        "      # -------------------------------------------------------------------------\n",
        "\n",
        "      # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "      # landsat_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/Extended/'+file_name+' - Landsat Data Extended.csv'\n",
        "      # -------------------------------------------------------------------------\n",
        "\n",
        "      # Save the individual Landsat 8 satellite Dataset to the specified Google Drive file path\n",
        "      save_df_to_drive(df_landsat, landsat_file_path)\n",
        "\n",
        "    except ValueError as ve:\n",
        "      print(f\"ValueError: {ve}\") # Handle the ValueError (No objects to concatenate)"
      ],
      "metadata": {
        "id": "exCNNXQkPN0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "853d7607-7329-42a1-eb6b-47a547903e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### merge_df\n",
        "Function that merges the individual filtered AmeriFlux flux tower dataset and the Landsat 8 satellite dataset for each Ameriflux flux tower and saves them to Google Drive file paths"
      ],
      "metadata": {
        "id": "q6c26274Pi1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_df(file_name):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that merges the individual filtered AmeriFlux flux tower dataset and the Landsat 8 satellite dataset for each Ameriflux flux tower and saves them to Google Drive file paths\n",
        "\n",
        "    parameter:  file_name -> file name of an individual Ameriflux flux tower dataset\n",
        "    return:     void\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Specify the Google Drive file paths where the filtered individual AmeriFlux flux tower Dataset and Landsat 8 satellite Dataset that corresponds to the input parameter file_name are stored\n",
        "  # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "  file_path_1 = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered/'+file_name+' - Flux Data.csv'\n",
        "  file_path_2 = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/First/'+file_name+' - Landsat Data.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "  # file_path_1 = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered Extended/'+file_name+' - Flux Data Extended.csv'\n",
        "  # file_path_2 = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/Extended/'+file_name+' - Landsat Data Extended.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # Load the CSV files into pandas DataFrames\n",
        "  df1 = pd.read_csv(file_path_1)                                # Pandas DataFrame that stores the individual AmeriFlux flux tower Dataset\n",
        "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n",
        "\n",
        "  file_name = file_name.split(' - ')[0]\n",
        "\n",
        "  # Merge the Pandas DataFrames based on the common column date\n",
        "  merged_df_outer = pd.merge(df1, df2, on='Date', how='outer')\n",
        "  merged_df_inner = pd.merge(df1, df2, on='Date', how='inner')\n",
        "\n",
        "  # 'how' parameter specifies the type of merge:\n",
        "  # - 'inner': Keeps only rows with matching 'ID' in both DataFrames (default).\n",
        "  # - 'left': Keeps all rows from df1 and matching rows from df2.\n",
        "  # - 'right': Keeps all rows from df2 and matching rows from df1.\n",
        "  # - 'outer': Keeps all rows from both DataFrames.\n",
        "\n",
        "\n",
        "  # Specify the Google Drive file paths where the outer merged datasets should be saved\n",
        "  # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "  merged_outer_data_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/'+file_name+' - Outer Merged.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "  # merged_outer_data_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged Extended/'+file_name+' - Outer Merged Extended.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # Save the outer merged Dataset to the specified Google Drive file path\n",
        "  save_df_to_drive(merged_df_outer, merged_outer_data_path)\n",
        "\n",
        "\n",
        "  # Specify the Google Drive file paths where the inner merged datasets should be saved\n",
        "  # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "  merged_inner_data_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/'+file_name+' - Inner Merged.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "  # merged_inner_data_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged Extended/'+file_name+' - Inner Merged Extended.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # Save the inner merged Dataset to the specified Google Drive file path\n",
        "  save_df_to_drive(merged_df_inner, merged_inner_data_path)"
      ],
      "metadata": {
        "id": "C0TFDj8_Pjic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "8c32104c-9113-4058-a376-b35b87181679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Individual Dataset Application"
      ],
      "metadata": {
        "id": "2CM4zbIJPwyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Extracting Original Flux Tower Datasets"
      ],
      "metadata": {
        "id": "lZpEEUv9P2yy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iuB4U9w0zf0h",
        "outputId": "13901ab3-3951-4c01-8cbe-eff17db60f0e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        }
      ],
      "source": [
        "# Specify the Google Drive file path of the individual AmeriFlux Flux Tower Datasets\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Original'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Original Extended'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# Change the current working directory to the specified folder\n",
        "os.chdir(folder_path)\n",
        "\n",
        "# Create an array to store file names\n",
        "Ameriflux_datasets = []\n",
        "\n",
        "# List files in the current directory and sort them alphabetically\n",
        "file_names = sorted(os.listdir())\n",
        "\n",
        "# Append the sorted file names to the Ameriflux_datasets array\n",
        "for file_name in file_names:\n",
        "    if os.path.isfile(file_name):\n",
        "        Ameriflux_datasets.append(file_name)\n",
        "\n",
        "# SANITY CHECK: correct number of file names/ datasets\n",
        "print(len(Ameriflux_datasets))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Acquire the Filtered Flux Tower and Satellite Datasets"
      ],
      "metadata": {
        "id": "iqaXkfI-QBm0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PSvzHppKzy11",
        "outputId": "e6cc81ee-a98a-47e5-ac7b-2a1e3056e003"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------- AMF_US-ASH_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-ASL_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-ASM_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Bi1_BASE_HH_9-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Bi2_BASE_HH_14-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Blo_BASE_HH_4-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-CGG_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-CMW_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-DPW_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-DS3_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Dia_BASE_HH_1-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Dmg_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-EDN_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Elm_BASE_HH_4-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Esm_BASE_HH_5-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Fmf_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Fuf_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Fwf_BASE_HH_8-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Hsm_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-KS1_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-KS2_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-KS3_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-LS1_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-LS2_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Lin_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-MtB_BASE_HH_4-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Myb_BASE_HH_13-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-ONA_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-PAS_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-PSH_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-PSL_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-RGB_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-RGo_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SP1_BASE_HH_4-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SP2_BASE_HH_3-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SP3_BASE_HH_3-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SP4_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SRC_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SRG_BASE_HH_15-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SRM_BASE_HH_26-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SRS_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Snd_BASE_HH_2-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Sne_BASE_HH_7-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Snf_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Srr_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SuM_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SuS_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SuW_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Ton_BASE_HH_17-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Tw1_BASE_HH_9-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Tw2_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Tw3_BASE_HH_5-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Tw4_BASE_HH_12-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Tw5_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Twt_BASE_HH_7-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Var_BASE_HH_18-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Whs_BASE_HH_21-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Wkg_BASE_HH_21-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xCL_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xDS_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xPU_BASE_HH_5-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xSB_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xSJ_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xSP_BASE_HH_7-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xSR_BASE_HH_7-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xTE_BASE_HH_7-5.csv -----------------------------------\n",
            "Dataset has been extracted\n"
          ]
        }
      ],
      "source": [
        "# Loop through the file names in the array and apply the 'data_aquisition' function\n",
        "for file_name in Ameriflux_datasets:\n",
        "  try:\n",
        "    print(\"-------------------------------- \"+file_name+\" -----------------------------------\")\n",
        "\n",
        "    # To speed up the process of each time an error broke my code I employed this if statement to see if the file had already been aquiared\n",
        "\n",
        "    # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "    flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered/'+file_name+' - Flux Data.csv'\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "    # flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered Extended/'+file_name+' - Flux Data Extended.csv'\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    if os.path.exists(flux_file_path):\n",
        "      print('Dataset has been extracted')\n",
        "    else:\n",
        "      data_aquisition(file_name)\n",
        "\n",
        "  except KeyError as e:\n",
        "    # Handle the KeyError\n",
        "    print(f\"Error: {e} - LE column does not exist\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Merge the Filtered Flux Tower and Satellite Datasets Together"
      ],
      "metadata": {
        "id": "Vy2MhDmZQoil"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "68-dFOzPPjBN",
        "outputId": "aaf2bfbd-19f3-45b3-b33b-b391be944979"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------- AMF_US-ASH_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-ASH_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-ASH_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-ASL_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-ASL_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-ASL_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-ASM_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-ASM_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-ASM_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Bi1_BASE_HH_9-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Bi1_BASE_HH_9-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Bi1_BASE_HH_9-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Bi2_BASE_HH_14-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Bi2_BASE_HH_14-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Bi2_BASE_HH_14-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Blo_BASE_HH_4-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-CGG_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-CGG_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-CGG_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-CMW_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-CMW_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-CMW_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-DPW_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-DPW_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-DPW_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-DS3_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-DS3_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-DS3_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Dia_BASE_HH_1-1.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Dmg_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Dmg_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Dmg_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-EDN_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-EDN_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-EDN_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Elm_BASE_HH_4-1.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Elm_BASE_HH_4-1.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Elm_BASE_HH_4-1.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Esm_BASE_HH_5-1.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Esm_BASE_HH_5-1.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Esm_BASE_HH_5-1.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Fmf_BASE_HH_6-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Fuf_BASE_HH_6-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Fwf_BASE_HH_8-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Hsm_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Hsm_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Hsm_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-KS1_BASE_HH_3-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-KS2_BASE_HH_3-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-KS3_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-KS3_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-KS3_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-LS1_BASE_HH_1-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-LS2_BASE_HH_1-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Lin_BASE_HH_2-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-MtB_BASE_HH_4-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-MtB_BASE_HH_4-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-MtB_BASE_HH_4-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Myb_BASE_HH_13-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Myb_BASE_HH_13-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Myb_BASE_HH_13-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-ONA_BASE_HH_3-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-ONA_BASE_HH_3-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-ONA_BASE_HH_3-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-PAS_BASE_HH_1-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-PSH_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-PSH_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-PSH_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-PSL_BASE_HH_1-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-RGB_BASE_HH_3-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-RGB_BASE_HH_3-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-RGB_BASE_HH_3-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-RGo_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-RGo_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-RGo_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SP1_BASE_HH_4-1.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-SP2_BASE_HH_3-1.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-SP3_BASE_HH_3-1.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-SP4_BASE_HH_3-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-SRC_BASE_HH_6-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SRC_BASE_HH_6-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SRC_BASE_HH_6-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SRG_BASE_HH_15-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SRG_BASE_HH_15-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SRG_BASE_HH_15-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SRM_BASE_HH_26-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SRM_BASE_HH_26-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SRM_BASE_HH_26-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SRS_BASE_HH_3-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SRS_BASE_HH_3-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SRS_BASE_HH_3-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Snd_BASE_HH_2-1.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Snd_BASE_HH_2-1.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Snd_BASE_HH_2-1.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Sne_BASE_HH_7-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Sne_BASE_HH_7-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Sne_BASE_HH_7-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Snf_BASE_HH_3-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Snf_BASE_HH_3-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Snf_BASE_HH_3-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Srr_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Srr_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Srr_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SuM_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SuM_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SuM_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SuS_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SuS_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SuS_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SuW_BASE_HH_2-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Ton_BASE_HH_17-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Ton_BASE_HH_17-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Ton_BASE_HH_17-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Tw1_BASE_HH_9-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Tw1_BASE_HH_9-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Tw1_BASE_HH_9-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Tw2_BASE_HH_2-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Tw3_BASE_HH_5-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Tw3_BASE_HH_5-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Tw3_BASE_HH_5-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Tw4_BASE_HH_12-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Tw4_BASE_HH_12-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Tw4_BASE_HH_12-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Tw5_BASE_HH_3-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Tw5_BASE_HH_3-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Tw5_BASE_HH_3-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Twt_BASE_HH_7-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Twt_BASE_HH_7-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Twt_BASE_HH_7-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Var_BASE_HH_18-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Var_BASE_HH_18-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Var_BASE_HH_18-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Whs_BASE_HH_21-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Whs_BASE_HH_21-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Whs_BASE_HH_21-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Wkg_BASE_HH_21-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Wkg_BASE_HH_21-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Wkg_BASE_HH_21-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xCL_BASE_HH_6-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xCL_BASE_HH_6-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xCL_BASE_HH_6-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xDS_BASE_HH_6-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xDS_BASE_HH_6-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xDS_BASE_HH_6-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xPU_BASE_HH_5-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xPU_BASE_HH_5-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xPU_BASE_HH_5-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xSB_BASE_HH_6-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xSB_BASE_HH_6-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xSB_BASE_HH_6-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xSJ_BASE_HH_6-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xSJ_BASE_HH_6-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xSJ_BASE_HH_6-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xSP_BASE_HH_7-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xSP_BASE_HH_7-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xSP_BASE_HH_7-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xSR_BASE_HH_7-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xSR_BASE_HH_7-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xSR_BASE_HH_7-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xTE_BASE_HH_7-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-baff30abb86d>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xTE_BASE_HH_7-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xTE_BASE_HH_7-5.csv - Inner Merged.csv'\n"
          ]
        }
      ],
      "source": [
        "# Loop through the file names in the array and apply the 'merge_df' function\n",
        "for file_name in Ameriflux_datasets:\n",
        "  print(\"-------------------------------- \"+file_name+\" -----------------------------------\")\n",
        "\n",
        "  # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "  flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered/'+file_name+' - Flux Data.csv'\n",
        "  landsat_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/First/'+file_name+' - Landsat Data.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "  # flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered Extended/'+file_name+' - Flux Data Extended.csv'\n",
        "  # landsat_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/Extended/'+file_name+' - Landsat Data Extended.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  if os.path.exists(flux_file_path) and os.path.exists(landsat_file_path):\n",
        "    merge_df(file_name)\n",
        "  else:\n",
        "    print('No Satellite Date (Likely it preceeds 2013)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXail52bEXQl"
      },
      "source": [
        "##### Combine All Individual Datasets into One"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Rxt5vz4-R2-N",
        "outputId": "41ef70a9-21e2-4cd2-a3dc-1236e2854dc7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Combined Dataset.csv'\n"
          ]
        }
      ],
      "source": [
        "# Define the path to the Google Drive folder where your CSV files are located\n",
        "\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged Extended'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through the files in the folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "    # Check if the file is a CSV file\n",
        "    if file_name.endswith('.csv'):\n",
        "        # Read the CSV file into a DataFrame and append it to the list\n",
        "        df = pd.read_csv(os.path.join(folder_path, file_name))\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames in the list into one DataFrame\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# combined_df_file_path = folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Combined Dataset with error.csv' # Including error messages and missing band values\n",
        "# save_df_to_drive(combined_df, combined_df_file_path)\n",
        "\n",
        "# Specify the column where NaN values should not be considered\n",
        "column_to_exclude = 'error'  # Replace with the name of the specific column\n",
        "df_combined_and_cleaned = combined_df.dropna(subset=[col for col in df.columns if col != column_to_exclude]) # Remove rows with NaN values, except in the specified column\n",
        "\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "combined_and_cleaned_df_file_path = folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Combined Dataset.csv'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# combined_and_cleaned_df_file_path = folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Combined Dataset Extended.csv'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "save_df_to_drive(df_combined_and_cleaned, combined_and_cleaned_df_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "hpehf4nl33L6",
        "outputId": "42637159-bf44-41e6-db80-532b156f9d10"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1442 entries, 0 to 1506\n",
            "Data columns (total 25 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Date              1442 non-null   object \n",
            " 1   Daily LE          1442 non-null   float64\n",
            " 2   Daily Count       1442 non-null   object \n",
            " 3   Landsat Image ID  1442 non-null   object \n",
            " 4   Latitude          1442 non-null   float64\n",
            " 5   Longitude         1442 non-null   float64\n",
            " 6   B1                1442 non-null   float64\n",
            " 7   B2                1442 non-null   float64\n",
            " 8   B3                1442 non-null   float64\n",
            " 9   B4                1442 non-null   float64\n",
            " 10  B5                1442 non-null   float64\n",
            " 11  B6                1442 non-null   float64\n",
            " 12  B7                1442 non-null   float64\n",
            " 13  B8                1442 non-null   float64\n",
            " 14  B9                1442 non-null   float64\n",
            " 15  B10               1442 non-null   float64\n",
            " 16  B11               1442 non-null   float64\n",
            " 17  BQA               1442 non-null   float64\n",
            " 18  Cloud Cover       1442 non-null   float64\n",
            " 19  NDVI              1442 non-null   object \n",
            " 20  EVI               1442 non-null   object \n",
            " 21  SAVI              1442 non-null   object \n",
            " 22  VARI              1442 non-null   object \n",
            " 23  NDWI              1442 non-null   object \n",
            " 24  error             0 non-null      object \n",
            "dtypes: float64(16), object(9)\n",
            "memory usage: 292.9+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Date     Daily LE Daily Count  \\\n",
              "0  20161003  2195.533135        2304   \n",
              "1  20161010  4261.502792        2304   \n",
              "2  20161019  3855.475241        2304   \n",
              "3  20161026  3410.497451        2304   \n",
              "4  20161104  1977.656382        2304   \n",
              "\n",
              "                               Landsat Image ID  Latitude  Longitude  \\\n",
              "0  LANDSAT/LC08/C01/T1_TOA/LC08_042035_20161003   36.1777  -120.2026   \n",
              "1  LANDSAT/LC08/C01/T1_TOA/LC08_043035_20161010   36.1777  -120.2026   \n",
              "2  LANDSAT/LC08/C01/T1_TOA/LC08_042035_20161019   36.1777  -120.2026   \n",
              "3  LANDSAT/LC08/C01/T1_TOA/LC08_043035_20161026   36.1777  -120.2026   \n",
              "4  LANDSAT/LC08/C01/T1_TOA/LC08_042035_20161104   36.1777  -120.2026   \n",
              "\n",
              "         B1        B2        B3        B4  ...         B10         B11  \\\n",
              "0  0.148876  0.132700  0.113312  0.103507  ...  293.519165  290.842529   \n",
              "1  0.121413  0.100615  0.087605  0.074336  ...  299.937988  298.319611   \n",
              "2  0.124823  0.103816  0.087938  0.070045  ...  294.045776  292.960663   \n",
              "3  0.119692  0.096548  0.078429  0.061975  ...  295.659698  293.916382   \n",
              "4  0.171797  0.148716  0.129624  0.112679  ...  284.465698  282.250305   \n",
              "\n",
              "      BQA  Cloud Cover      NDVI       EVI      SAVI      VARI      NDWI error  \n",
              "0  2720.0        22.89  0.487626  0.531719  0.326894  0.116562 -0.452379   NaN  \n",
              "1  2720.0        40.73  0.545663  0.472723  0.323774  0.216369 -0.485429   NaN  \n",
              "2  2720.0         0.15  0.582568  0.538769  0.350963  0.330327 -0.502462   NaN  \n",
              "3  2720.0         4.15  0.556065  0.448735  0.298876  0.375183 -0.469467   NaN  \n",
              "4  6848.0        11.01  0.469332  0.570964  0.323322  0.181057 -0.412955   NaN  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36bc903e-2e91-4265-9fbc-589852667242\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Daily LE</th>\n",
              "      <th>Daily Count</th>\n",
              "      <th>Landsat Image ID</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>...</th>\n",
              "      <th>B10</th>\n",
              "      <th>B11</th>\n",
              "      <th>BQA</th>\n",
              "      <th>Cloud Cover</th>\n",
              "      <th>NDVI</th>\n",
              "      <th>EVI</th>\n",
              "      <th>SAVI</th>\n",
              "      <th>VARI</th>\n",
              "      <th>NDWI</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20161003</td>\n",
              "      <td>2195.533135</td>\n",
              "      <td>2304</td>\n",
              "      <td>LANDSAT/LC08/C01/T1_TOA/LC08_042035_20161003</td>\n",
              "      <td>36.1777</td>\n",
              "      <td>-120.2026</td>\n",
              "      <td>0.148876</td>\n",
              "      <td>0.132700</td>\n",
              "      <td>0.113312</td>\n",
              "      <td>0.103507</td>\n",
              "      <td>...</td>\n",
              "      <td>293.519165</td>\n",
              "      <td>290.842529</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>22.89</td>\n",
              "      <td>0.487626</td>\n",
              "      <td>0.531719</td>\n",
              "      <td>0.326894</td>\n",
              "      <td>0.116562</td>\n",
              "      <td>-0.452379</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20161010</td>\n",
              "      <td>4261.502792</td>\n",
              "      <td>2304</td>\n",
              "      <td>LANDSAT/LC08/C01/T1_TOA/LC08_043035_20161010</td>\n",
              "      <td>36.1777</td>\n",
              "      <td>-120.2026</td>\n",
              "      <td>0.121413</td>\n",
              "      <td>0.100615</td>\n",
              "      <td>0.087605</td>\n",
              "      <td>0.074336</td>\n",
              "      <td>...</td>\n",
              "      <td>299.937988</td>\n",
              "      <td>298.319611</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>40.73</td>\n",
              "      <td>0.545663</td>\n",
              "      <td>0.472723</td>\n",
              "      <td>0.323774</td>\n",
              "      <td>0.216369</td>\n",
              "      <td>-0.485429</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20161019</td>\n",
              "      <td>3855.475241</td>\n",
              "      <td>2304</td>\n",
              "      <td>LANDSAT/LC08/C01/T1_TOA/LC08_042035_20161019</td>\n",
              "      <td>36.1777</td>\n",
              "      <td>-120.2026</td>\n",
              "      <td>0.124823</td>\n",
              "      <td>0.103816</td>\n",
              "      <td>0.087938</td>\n",
              "      <td>0.070045</td>\n",
              "      <td>...</td>\n",
              "      <td>294.045776</td>\n",
              "      <td>292.960663</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.582568</td>\n",
              "      <td>0.538769</td>\n",
              "      <td>0.350963</td>\n",
              "      <td>0.330327</td>\n",
              "      <td>-0.502462</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20161026</td>\n",
              "      <td>3410.497451</td>\n",
              "      <td>2304</td>\n",
              "      <td>LANDSAT/LC08/C01/T1_TOA/LC08_043035_20161026</td>\n",
              "      <td>36.1777</td>\n",
              "      <td>-120.2026</td>\n",
              "      <td>0.119692</td>\n",
              "      <td>0.096548</td>\n",
              "      <td>0.078429</td>\n",
              "      <td>0.061975</td>\n",
              "      <td>...</td>\n",
              "      <td>295.659698</td>\n",
              "      <td>293.916382</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>4.15</td>\n",
              "      <td>0.556065</td>\n",
              "      <td>0.448735</td>\n",
              "      <td>0.298876</td>\n",
              "      <td>0.375183</td>\n",
              "      <td>-0.469467</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20161104</td>\n",
              "      <td>1977.656382</td>\n",
              "      <td>2304</td>\n",
              "      <td>LANDSAT/LC08/C01/T1_TOA/LC08_042035_20161104</td>\n",
              "      <td>36.1777</td>\n",
              "      <td>-120.2026</td>\n",
              "      <td>0.171797</td>\n",
              "      <td>0.148716</td>\n",
              "      <td>0.129624</td>\n",
              "      <td>0.112679</td>\n",
              "      <td>...</td>\n",
              "      <td>284.465698</td>\n",
              "      <td>282.250305</td>\n",
              "      <td>6848.0</td>\n",
              "      <td>11.01</td>\n",
              "      <td>0.469332</td>\n",
              "      <td>0.570964</td>\n",
              "      <td>0.323322</td>\n",
              "      <td>0.181057</td>\n",
              "      <td>-0.412955</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36bc903e-2e91-4265-9fbc-589852667242')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36bc903e-2e91-4265-9fbc-589852667242 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36bc903e-2e91-4265-9fbc-589852667242');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dac9acb5-9077-4daf-8765-ed6ffe6290ce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dac9acb5-9077-4daf-8765-ed6ffe6290ce')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dac9acb5-9077-4daf-8765-ed6ffe6290ce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# SANITY CHECK: check number of columns and rows, variables and their data types\n",
        "print(df_combined_and_cleaned.info())\n",
        "df_combined_and_cleaned.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Process the Single Dataset for Machine Learning Application"
      ],
      "metadata": {
        "id": "owMiSbbcRCi2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "iL8ITyVu7kmg",
        "outputId": "6c33fcf2-ce4a-471e-92fa-a6df8f69a379"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date).csv'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Daily LE      Date        B1        B2        B3        B4        B5  \\\n",
              "0  2195.533135  20161003  0.148876  0.132700  0.113312  0.103507  0.300521   \n",
              "1  4261.502792  20161010  0.121413  0.100615  0.087605  0.074336  0.252893   \n",
              "2  3855.475241  20161019  0.124823  0.103816  0.087938  0.070045  0.265555   \n",
              "3  3410.497451  20161026  0.119692  0.096548  0.078429  0.061975  0.217233   \n",
              "4  1977.656382  20161104  0.171797  0.148716  0.129624  0.112679  0.311990   \n",
              "\n",
              "         B6        B7        B8        B9         B10         B11     BQA  \\\n",
              "0  0.170895  0.102205  0.113339  0.001579  293.519165  290.842529  2720.0   \n",
              "1  0.142067  0.081778  0.082153  0.000923  299.937988  298.319611  2720.0   \n",
              "2  0.137159  0.074076  0.079694  0.001435  294.045776  292.960663  2720.0   \n",
              "3  0.110441  0.059190  0.070842  0.000960  295.659698  293.916382  2720.0   \n",
              "4  0.172616  0.107599  0.122055  0.029218  284.465698  282.250305  6848.0   \n",
              "\n",
              "   Cloud Cover      NDVI       EVI      SAVI      VARI      NDWI  \n",
              "0        22.89  0.487626  0.531719  0.326894  0.116562 -0.452379  \n",
              "1        40.73  0.545663  0.472723  0.323774  0.216369 -0.485429  \n",
              "2         0.15  0.582568  0.538769  0.350963  0.330327 -0.502462  \n",
              "3         4.15  0.556065  0.448735  0.298876  0.375183 -0.469467  \n",
              "4        11.01  0.469332  0.570964  0.323322  0.181057 -0.412955  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f61fad8e-9503-4d0d-b3eb-25c1d55f5bbc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Daily LE</th>\n",
              "      <th>Date</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B5</th>\n",
              "      <th>B6</th>\n",
              "      <th>B7</th>\n",
              "      <th>B8</th>\n",
              "      <th>B9</th>\n",
              "      <th>B10</th>\n",
              "      <th>B11</th>\n",
              "      <th>BQA</th>\n",
              "      <th>Cloud Cover</th>\n",
              "      <th>NDVI</th>\n",
              "      <th>EVI</th>\n",
              "      <th>SAVI</th>\n",
              "      <th>VARI</th>\n",
              "      <th>NDWI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2195.533135</td>\n",
              "      <td>20161003</td>\n",
              "      <td>0.148876</td>\n",
              "      <td>0.132700</td>\n",
              "      <td>0.113312</td>\n",
              "      <td>0.103507</td>\n",
              "      <td>0.300521</td>\n",
              "      <td>0.170895</td>\n",
              "      <td>0.102205</td>\n",
              "      <td>0.113339</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>293.519165</td>\n",
              "      <td>290.842529</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>22.89</td>\n",
              "      <td>0.487626</td>\n",
              "      <td>0.531719</td>\n",
              "      <td>0.326894</td>\n",
              "      <td>0.116562</td>\n",
              "      <td>-0.452379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4261.502792</td>\n",
              "      <td>20161010</td>\n",
              "      <td>0.121413</td>\n",
              "      <td>0.100615</td>\n",
              "      <td>0.087605</td>\n",
              "      <td>0.074336</td>\n",
              "      <td>0.252893</td>\n",
              "      <td>0.142067</td>\n",
              "      <td>0.081778</td>\n",
              "      <td>0.082153</td>\n",
              "      <td>0.000923</td>\n",
              "      <td>299.937988</td>\n",
              "      <td>298.319611</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>40.73</td>\n",
              "      <td>0.545663</td>\n",
              "      <td>0.472723</td>\n",
              "      <td>0.323774</td>\n",
              "      <td>0.216369</td>\n",
              "      <td>-0.485429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3855.475241</td>\n",
              "      <td>20161019</td>\n",
              "      <td>0.124823</td>\n",
              "      <td>0.103816</td>\n",
              "      <td>0.087938</td>\n",
              "      <td>0.070045</td>\n",
              "      <td>0.265555</td>\n",
              "      <td>0.137159</td>\n",
              "      <td>0.074076</td>\n",
              "      <td>0.079694</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>294.045776</td>\n",
              "      <td>292.960663</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.582568</td>\n",
              "      <td>0.538769</td>\n",
              "      <td>0.350963</td>\n",
              "      <td>0.330327</td>\n",
              "      <td>-0.502462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3410.497451</td>\n",
              "      <td>20161026</td>\n",
              "      <td>0.119692</td>\n",
              "      <td>0.096548</td>\n",
              "      <td>0.078429</td>\n",
              "      <td>0.061975</td>\n",
              "      <td>0.217233</td>\n",
              "      <td>0.110441</td>\n",
              "      <td>0.059190</td>\n",
              "      <td>0.070842</td>\n",
              "      <td>0.000960</td>\n",
              "      <td>295.659698</td>\n",
              "      <td>293.916382</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>4.15</td>\n",
              "      <td>0.556065</td>\n",
              "      <td>0.448735</td>\n",
              "      <td>0.298876</td>\n",
              "      <td>0.375183</td>\n",
              "      <td>-0.469467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1977.656382</td>\n",
              "      <td>20161104</td>\n",
              "      <td>0.171797</td>\n",
              "      <td>0.148716</td>\n",
              "      <td>0.129624</td>\n",
              "      <td>0.112679</td>\n",
              "      <td>0.311990</td>\n",
              "      <td>0.172616</td>\n",
              "      <td>0.107599</td>\n",
              "      <td>0.122055</td>\n",
              "      <td>0.029218</td>\n",
              "      <td>284.465698</td>\n",
              "      <td>282.250305</td>\n",
              "      <td>6848.0</td>\n",
              "      <td>11.01</td>\n",
              "      <td>0.469332</td>\n",
              "      <td>0.570964</td>\n",
              "      <td>0.323322</td>\n",
              "      <td>0.181057</td>\n",
              "      <td>-0.412955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f61fad8e-9503-4d0d-b3eb-25c1d55f5bbc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f61fad8e-9503-4d0d-b3eb-25c1d55f5bbc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f61fad8e-9503-4d0d-b3eb-25c1d55f5bbc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d1ea4b6-2ef0-4b3f-9c3b-024db956dec2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d1ea4b6-2ef0-4b3f-9c3b-024db956dec2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d1ea4b6-2ef0-4b3f-9c3b-024db956dec2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Extract only the neccesary variables for machine learning model dataset\n",
        "\n",
        "## ------------------------------------------------------------------------ Without Date ------------------------------------------------------------------------\n",
        "# ml_columns = ['Daily LE', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'BQA', 'Cloud Cover', 'NDVI', 'EVI', 'SAVI', 'VARI', 'NDWI']\n",
        "# ml_df = df_combined_and_cleaned[ml_columns]\n",
        "\n",
        "# # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "# # ml_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset.csv'\n",
        "# # -------------------------------------------------------------------------\n",
        "\n",
        "# # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# ml_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset Extended.csv'\n",
        "# # -------------------------------------------------------------------------\n",
        "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# -------------------------------------------------------------------------- With Date --------------------------------------------------------------------------\n",
        "ml_columns = ['Daily LE', 'Date', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'BQA', 'Cloud Cover', 'NDVI', 'EVI', 'SAVI', 'VARI', 'NDWI']\n",
        "ml_df = df_combined_and_cleaned[ml_columns]\n",
        "\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "ml_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date).csv'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# ml_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset Extended (Date).csv'\n",
        "# -------------------------------------------------------------------------\n",
        "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "save_df_to_drive(ml_df, ml_file_path)\n",
        "\n",
        "ml_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Date Variable Variation"
      ],
      "metadata": {
        "id": "Y3dgARxrRhp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_epoch(df):\n",
        "  \"\"\"\n",
        "  Function that converts the date variable to Unix Epoch (i.e. numeric form) and removes the date variable\n",
        "\n",
        "    parameter:  df -> final machine learning Pandas DataFrame\n",
        "    return:     df_epoch -> machine learning Pandas DataFrame with Unix Epoch instead of date\n",
        "  \"\"\"\n",
        "  df_epoch = df\n",
        "\n",
        "  # Date was converted to Epoch (numeric representation)\n",
        "  df_epoch['Date'] = pd.to_datetime(df_epoch['Date'], format='%Y%m%d')\n",
        "  df_epoch['Date Epoch'] = df_epoch['Date'].astype(int) // 10**9  # Convert to seconds since epoch\n",
        "  df_epoch = df_epoch.drop('Date', axis=1)\n",
        "\n",
        "  return df_epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "n5ItrionzLj8",
        "outputId": "034dd6ad-1995-4c02-e9d6-6e0115c7f555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def df_epoch_and(df):\n",
        "  \"\"\"\n",
        "  Function that converts the date variable to Unix Epoch (i.e. numeric form) and separates the day, month and year variables and removes the date variable\n",
        "\n",
        "    parameter:  df -> final machine learning Pandas DataFrame\n",
        "    return:     df_epoch_and -> machine learning Pandas DataFrame with Unix Epoch and day, month and year variables instead of date\n",
        "  \"\"\"\n",
        "\n",
        "  df_epoch_and = df\n",
        "  df_epoch_and['Date'] = pd.to_datetime(df_epoch_and['Date'], format='%Y%m%d')\n",
        "  df_epoch_and['Date Epoch'] = df_epoch_and['Date'].astype(int) // 10**9  # Convert to seconds since epoch\n",
        "\n",
        "  df_epoch_and['Year'] = df_epoch_and['Date'].dt.year\n",
        "  df_epoch_and['Month'] = df_epoch_and['Date'].dt.month\n",
        "  df_epoch_and['Day'] = df_epoch_and['Date'].dt.day\n",
        "  df_epoch_and = df_epoch_and.drop('Date', axis=1)\n",
        "\n",
        "  return df_epoch_and"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YKsD3hV90sVl",
        "outputId": "05e0e01f-8e64-422e-bc5e-5776267a6011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_epoch = df_epoch(ml_df)\n",
        "df_epoch_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date) - epoch.csv'\n",
        "save_df_to_drive(df_epoch, df_epoch_file_path)\n",
        "\n",
        "df_epoch_and = df_epoch_and(ml_df)\n",
        "df_epoch_and_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date) - epoch, year, month, day.csv'\n",
        "save_df_to_drive(df_epoch_and, df_epoch_and_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "5pNju-SP1Lmp",
        "outputId": "3bab80a5-8810-4fad-9071-67fc7628886f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date) - epoch, year, month, day.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-e3d0bfda7215>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_epoch_and['Date'] = pd.to_datetime(df_epoch_and['Date'], format='%Y%m%d')\n",
            "<ipython-input-50-e3d0bfda7215>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_epoch_and['Date Epoch'] = df_epoch_and['Date'].astype(int) // 10**9  # Convert to seconds since epoch\n",
            "<ipython-input-50-e3d0bfda7215>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_epoch_and['Year'] = df_epoch_and['Date'].dt.year\n",
            "<ipython-input-50-e3d0bfda7215>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_epoch_and['Month'] = df_epoch_and['Date'].dt.month\n",
            "<ipython-input-50-e3d0bfda7215>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_epoch_and['Day'] = df_epoch_and['Date'].dt.day\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "GDwY-VJ1tbkG",
        "0Ofb6MgatwJt",
        "cFpAcbzvt-GT",
        "T9EPLy1luvNU",
        "6gjANH7hyJiR",
        "PLoKcu4H6ihS",
        "TE0HGzsfyaPi",
        "qNG6_T7uyjfO",
        "7Cju7kPvyUGd",
        "dOa3asdjuvgl",
        "_Sg9DvmEuvsh",
        "AW7zVy6qvXFe",
        "SDxovsU2vg_7",
        "vOQ7ctGsvsuM",
        "rDGSPKHHv6_8",
        "PZVAIMBQwDm6",
        "I4X_hLrCwQcD",
        "H8yPWOw7wYaC",
        "r4BAySrRw8Jj",
        "u57QZ1lGw8oa",
        "9F6Es3r6zHOh",
        "Qfms_gxBO4E4",
        "aDXXW1r7PCTA",
        "9BUk89Z7PNfF",
        "q6c26274Pi1l",
        "iqaXkfI-QBm0",
        "Vy2MhDmZQoil",
        "gXail52bEXQl",
        "owMiSbbcRCi2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}