{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_epAAq6tS59"
      },
      "source": [
        "# Data Aquisition, Processing and Collation\n",
        "The following Jupyter Notebook collects the two datasets necessary for the MAPWAPS project application, namely: flux tower data and satellite data. It proceses the two datasets individually and then combines them to produce a single final dataset ready to be used in machine learning model training, valdation and testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDwY-VJ1tbkG"
      },
      "source": [
        "## Library and Function Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell imports several essential libraries and sets up functionalities in the Jupyter Notebook, ensuring that they are readily available for implementation and utilization later in the code"
      ],
      "metadata": {
        "id": "YM3i5VCF79ao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "ap77KRGhtXYu",
        "outputId": "4e5cc3f9-96ef-49af-a960-1e49265c1afc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.8.post2-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.8.post2 snuggs-1.4.7\n",
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=-kondMN2ayiZ88cJO_ldgQztCPzjFkr1eW0YieltP2o&tc=fKxmZp0nuiW-lS2vQtRdBDL9ssM3A50OCF4KZs-T2P4&cc=fmcyjFg__FeqWQ0rmwUw03t8YTZKu7RLrI5gBIb3uNw\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AfJohXmlug9sS55AgKM6bqDvVHOLNSnNaLeL5yojC_1oGxN9VR4b-yNvVuU\n",
            "\n",
            "Successfully saved authorization token.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio\n",
        "import ee\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geemap\n",
        "import re\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Authenticate with Earth Engine (requires user interaction)\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the Earth Engine Python API\n",
        "ee.Initialize()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ofb6MgatwJt"
      },
      "source": [
        "## Miscellaneous Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFpAcbzvt-GT"
      },
      "source": [
        "### save_df_to_drive\n",
        "Function that saves a Pandas DataFrame as a csv file to a Google Drive folder specified by a Google Drive file path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "VWdEqO_utw51",
        "outputId": "71bfb29a-7329-4477-d402-3450152375e2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def save_df_to_drive(df, file_path_in_google_drive):\n",
        "  \"\"\"\n",
        "  Function that saves a Pandas DataFrame as a csv file to a Google Drive folder specified by a google drive file path\n",
        "\n",
        "    parameter:  dataframe -> the Pandas DataFrame needing to be saved\n",
        "                file_path_in_drive -> Google Drive folder file path that will store the csv file\n",
        "    return:     void\n",
        "\n",
        "  \"\"\"\n",
        "  try:\n",
        "      # Ensure the destination directory exists\n",
        "      destination_dir = os.path.dirname(file_path_in_google_drive)\n",
        "      os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "      # Save the DataFrame to the specified file path in Google Drive\n",
        "      df.to_csv(file_path_in_google_drive, index=False)\n",
        "\n",
        "      print(f\"DataFrame saved to Google Drive at '{file_path_in_google_drive}'\")\n",
        "\n",
        "  except Exception as e:\n",
        "      print(\"An error occurred:\", str(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9EPLy1luvNU"
      },
      "source": [
        "## Flux Tower Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gjANH7hyJiR"
      },
      "source": [
        "### timestamp_separate\n",
        "Function that uses string handlng techniques to seperate the TIME_STAMP (YYYYMMDDHHMM) into TIME_STAMP_DATE (YYYYMMDD) and TIME_STAMP_TIME (HHMM) in order to isolate the date variable for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qJdLHBhpyK7s",
        "outputId": "eed78c80-a26f-42ad-9bc7-5894e666cfec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def timestamp_separate(df):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that uses string handling techniques to separate the flux tower variable TIME_STAMP (YYYYMMDDHHMM)\n",
        "  into TIME_STAMP_DATE (YYYYMMDD) and TIME_STAMP_TIME (HHMM) in order to isolate the date variable for later use\n",
        "\n",
        "    parameter:  df -> the Pandas DataFrame storing the original, unfiltered flux tower data\n",
        "    return:     df_time_seperated -> the Pandas DataFrame with manipulated date and time variables\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Manipulates the TIMESTAMP (both START and END) columns to split into DATE and TIME separately\n",
        "  # Convert TIMESTAMP columns to string\n",
        "  df['TIMESTAMP_START'] = df['TIMESTAMP_START'].astype(str)\n",
        "  df['TIMESTAMP_END'] = df['TIMESTAMP_END'].astype(str)\n",
        "\n",
        "  # Extract TIMESTAMP_DATE (YYMMDD) and TIMESTAMP_TIME (HHMM) (for both START and END) with string handling principles\n",
        "  df['TIMESTAMP_START_DATE'] = df['TIMESTAMP_START'].str[:8]\n",
        "  df['TIMESTAMP_START_TIME'] = df['TIMESTAMP_START'].str[8:]\n",
        "  df['TIMESTAMP_END_DATE'] = df['TIMESTAMP_END'].str[:8]\n",
        "  df['TIMESTAMP_END_TIME'] = df['TIMESTAMP_END'].str[8:]\n",
        "\n",
        "  # @ this stage the count variable should be 48 because the sampling rate is 30 minutes (24hrs x 2) and no entries have been removed\n",
        "  df['COUNT'] = df.groupby('TIMESTAMP_START_DATE')['TIMESTAMP_START_DATE'].transform('count')\n",
        "\n",
        "  # Specify TIMESTAMP columns order\n",
        "  start_columns = [\n",
        "      'TIMESTAMP_START', 'TIMESTAMP_START_DATE', 'TIMESTAMP_START_TIME',\n",
        "      'TIMESTAMP_END', 'TIMESTAMP_END_DATE', 'TIMESTAMP_END_TIME'\n",
        "  ]\n",
        "\n",
        "  # Define the df order with TIMESTAMP columns first and remaining columns in their original order\n",
        "  desired_order = start_columns + [col for col in df.columns if col not in start_columns]\n",
        "  df_time_seperated = df[desired_order]\n",
        "\n",
        "  return df_time_seperated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLoKcu4H6ihS"
      },
      "source": [
        "### check_LE\n",
        "Function that check if a dataset has an LE column and if not finds a LE column derivation and renames it LE for simplified use\n",
        "\n",
        "- Note: LE column derivation refers to a column that stores LE values but under a different column name (e.g. LE_1.1.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "g7wSNsGD6oqn",
        "outputId": "c38412c0-06f1-4e57-b478-0458efb8f021"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def check_LE(df):\n",
        "    \"\"\"\n",
        "    Function that check if a dataset has an LE column and if not finds a LE column derivation and renames it LE for simplified future use\n",
        "      Note: LE column derivation refers to a column that stores LE values but under a different column name (e.g. LE_1.1.1)\n",
        "\n",
        "    parameter:  df -> the Pandas DataFrame storing the original flux tower data (with LE or LE derived columns)\n",
        "    return:     df_with_LE -> the Pandas DataFrame with LE column name\n",
        "\n",
        "    \"\"\"\n",
        "    column_name = 'LE'                        # Column of interest is the Latent Heat Flux (LE)\n",
        "    df_with_LE = df\n",
        "\n",
        "    if not column_name in df.columns:         # The Pandas DataFrame does not have a column with name 'LE'\n",
        "      try:\n",
        "          # Find the first column that starts with 'LE'\n",
        "          LE_column = next(col for col in df.columns if col.startswith('LE'))\n",
        "\n",
        "          # Rename the column to 'LE'\n",
        "          df_with_LE = df.rename(columns={LE_column: 'LE'}, inplace=True)\n",
        "      except StopIteration:\n",
        "          # The Pandas DataFrame does not have a column name that starts with 'LE'\n",
        "          print(\"No column starts with 'LE'\")\n",
        "\n",
        "    return df_with_LE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE0HGzsfyaPi"
      },
      "source": [
        "### remove_null\n",
        "Function that removes any data entry/ row that has a null (-9999) Latent Heat Flux (LE) variable\n",
        "- there is commented out section of code that will remove any entry with a null value (LE variable or otherwise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "x81zBZbuyabK",
        "outputId": "e7733e23-33c5-4792-cf96-4eeffb1d094a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def remove_null(df):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that removes any data entry/ row that has a null (-9999) Latent Heat Flux (LE) variable\n",
        "\n",
        "    parameter:  df -> the Pandas DataFrame with LE null (-9999) values\n",
        "    return:     df_without_LE_null_values -> the Pandas DataFrame with removed LE null (-9999) values\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # # ----------------------- use if all entries with null values need removal -----------------------\n",
        "  # # Removes any row with a null (-9999) value\n",
        "  # columns_to_check = df.columns[2:]\n",
        "  # void_filter_boolean = df[columns_to_check].apply(lambda x: (x != -9999).all(), axis=1) # creates a boolean mask to identify the presence of -9999 values\n",
        "  # df_without_null_values = df[void_filter_boolean] # applies mask to df\n",
        "  # # ------------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Removes any row with a LE column null (-9999) value\n",
        "  df = df[df['LE'] != -9999]\n",
        "  del df['COUNT']\n",
        "  df['COUNT'] = df.groupby('TIMESTAMP_START_DATE')['TIMESTAMP_START_DATE'].transform('count')     # Counts the number of entries per date\n",
        "  df_without_LE_null_values = df\n",
        "\n",
        "  return df_without_LE_null_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNG6_T7uyjfO"
      },
      "source": [
        "### group_df\n",
        "Function that will group a dataframe by the date and add up each of its other columns - this is because we want to deal with daily ET estimates.\n",
        "- It will also filter the dataframe to obtain only the neccessary variables: Date, LE, COUNT\n",
        "- If the COUNT variable is not 2304 (48 x 48) then that row is removed because it signals an 'incomplete' dataset in that due to null value removals, there is not a full days worth of collected data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oDHiJqd0yjpY",
        "outputId": "44ad99e1-6934-4bf7-df23-32996bbfb127"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def group_df(df):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that groups a Pandas DataFrame by the date variable and adds up the other columns\n",
        "\n",
        "    parameter:  df -> the Pandas DataFrame with half hourly data readings (i.e. 48 readings per day - unless null values have been removed)\n",
        "    return:     df_grouped -> the Pandas DataFrame with grouped entries/ rows and daily LE values\n",
        "                              (only entries with a full day of recordings will be included - i.e. the daily count of 2304 = 48 x 48)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  df_simplified = df[['TIMESTAMP_START_DATE','LE','COUNT']]         # Creates a new filtered Pandad DataFrame with only the important columns\n",
        "  # df_simplified.head()           # Uncomment to ensure proper dataframe simplification\n",
        "\n",
        "  # Group by 'TIMESTAMP_START_DATE' and sum the 'LE' and 'COUNT' columns\n",
        "  df_grouped = df_simplified.groupby('TIMESTAMP_START_DATE').agg({'LE': 'sum', 'COUNT': 'sum'}).reset_index()\n",
        "  df_grouped.rename(columns={'TIMESTAMP_START_DATE': 'DATE', 'LE': 'DAILY LE', 'COUNT': 'DAILY COUNT'}, inplace=True) # Rename the columns\n",
        "\n",
        "  # Drop all 'incomplete' entries (those that do not have a days worth of data)\n",
        "  df_grouped = df_grouped[df_grouped['DAILY COUNT'] == 2304]\n",
        "\n",
        "  return df_grouped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cju7kPvyUGd"
      },
      "source": [
        "## Landsat Satellite Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOa3asdjuvgl"
      },
      "source": [
        "### Image Bands and Plant Indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sg9DvmEuvsh"
      },
      "source": [
        "#### get_landsat_bands\n",
        "Function that extracts the multispectral bands from a Landsat 8 satellite image of a co-ordinate specified location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_vY4T9EOvPT0",
        "outputId": "eddc041a-9f1b-4e0e-9952-e5cc496104a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_landsat_bands(image_id, latitude, longitude):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that extracts the multispectral bands from a Landsat 8 satellite image of a co-ordinate specified location\n",
        "\n",
        "    parameter:  image_id -> unique Landsat 8 image ID\n",
        "                latitude -> latitude co-ordinate of desired location\n",
        "                longitude -> longitude co-ordinate of desired location\n",
        "    return:     band_dict -> dictionary of multispectral band values for a specified location with labels B1 - B11\n",
        "\n",
        "  \"\"\"\n",
        "  try:\n",
        "      # Load the Landsat image by its ID\n",
        "      landsat_image = ee.Image(image_id)\n",
        "\n",
        "      # Define a point geometry for the specified latitude and longitude\n",
        "      point_geometry = ee.Geometry.Point([longitude, latitude])\n",
        "\n",
        "      # Use the .sample() method to extract pixel values at the specified geometry\n",
        "      # This will create a feature collection containing the pixel values\n",
        "      pixel_values = landsat_image.sample(point_geometry, 30)  # 30 meters scale for Landsat\n",
        "\n",
        "      # Initialize an empty dictionary to store the band values\n",
        "      band_dict = {}\n",
        "\n",
        "      # Extract band values from the feature collection and add them to the dictionary\n",
        "      for band_name in landsat_image.bandNames().getInfo():\n",
        "          band_value = pixel_values.first().get(band_name).getInfo()\n",
        "          band_dict[band_name] = band_value\n",
        "\n",
        "      return band_dict\n",
        "\n",
        "  except ee.EEException as e:\n",
        "      return {\"error\": \"An Earth Engine exception occurred: \" + str(e)}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW7zVy6qvXFe"
      },
      "source": [
        "#### get_cloud_cover\n",
        "Function that extracts the cloud cover percentage from a satellite image specified by a Landsat 8 image ID\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "K21I80dlvZY4",
        "outputId": "39a814a1-b7ef-465d-ef3d-28bc9c2014f0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_cloud_cover(image_id):\n",
        "  \"\"\"\n",
        "  Function that extracts the cloud cover percentage from a satellite image specified by a Landsat 8 image ID\n",
        "\n",
        "    parameter:  image_id -> Landsat 8 image ID\n",
        "    return:     cloud_cover_rounded -> percentage cloud cover rounded to 3 decimal points\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Load the Landsat image using the provided image_id\n",
        "  image = ee.Image(image_id)\n",
        "\n",
        "  # Get the cloud cover property\n",
        "  cloud_cover = image.get('CLOUD_COVER').getInfo()\n",
        "\n",
        "  # Round the cloud cover percentage to 3 decimal places\n",
        "  cloud_cover_rounded = round(cloud_cover, 3)\n",
        "\n",
        "  return cloud_cover_rounded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDxovsU2vg_7"
      },
      "source": [
        "#### calculate_ndvi\n",
        "Function that calculates the Normalised Diffference Vegetation Index (NDVI)\n",
        "\n",
        "$ NDVI = \\frac{NIR - Red}{NIR + Red} \\in (-1, 1)$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2SxpBwXSvmrb",
        "outputId": "4262a412-ae2c-4b2d-9684-b97a4387ebf9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def calculate_ndvi(band_dict):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that calculates the Normalised Diffference Vegetation Index (NDVI) from the multispectral bands of a satellite image\n",
        "\n",
        "    parameter:  band_dict -> dictionary of multispectral band values\n",
        "    return:     ndvi -> Normalised Diffference Vegetation Index (NDVI) value\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "      # Extract the values for the NIR (Near Infrared) and Red bands from the dictionary\n",
        "      nir = band_dict['B5']  # Assuming 'B5' is the NIR band\n",
        "      red = band_dict['B4']  # Assuming 'B4' is the Red band\n",
        "\n",
        "      # Calculate NDVI\n",
        "      ndvi = (nir - red) / (nir + red)\n",
        "\n",
        "      return ndvi\n",
        "\n",
        "  except KeyError:\n",
        "      return {\"error\": \"Required bands (NIR and Red) not found in the band dictionary.\"}\n",
        "  except ZeroDivisionError:\n",
        "      return {\"error\": \"Division by zero error. Check if NIR + Red is zero.\"}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOQ7ctGsvsuM"
      },
      "source": [
        "#### calculate_vari\n",
        "Function that calculates the Visible Atmospherically Resistant Index (VARI)\n",
        "\n",
        "$VARI = \\frac{Green - Red}{Green + Red - Blue}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "2BowJQf9vzP1",
        "outputId": "f43eafb0-40e5-49f5-9a96-6ce051e2a151"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def calculate_vari(band_dict):\n",
        "  \"\"\"\n",
        "  Function that calculates the Visible Atmospherically Resistant Index (VARI) from the multispectral bands of a satellite image\n",
        "\n",
        "    parameter:  band_dict -> dictionary of multispectral band values\n",
        "    return:     vari -> Visible Atmospherically Resistant Index (VARI) value\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "      # Extract the values for the Blue, Red, and Green bands from the dictionary\n",
        "      blue = band_dict['B2']  # Assuming 'B2' is the Blue band\n",
        "      red = band_dict['B4']   # Assuming 'B4' is the Red band\n",
        "      green = band_dict['B3'] # Assuming 'B3' is the Green band\n",
        "\n",
        "      # Calculate VARI\n",
        "      vari = (green - red) / (green + red - blue)\n",
        "\n",
        "      return vari\n",
        "\n",
        "  except KeyError:\n",
        "      return {\"error\": \"Required bands (Blue, Red, and Green) not found in the band dictionary.\"}\n",
        "  except ZeroDivisionError:\n",
        "      return {\"error\": \"Division by zero error. Check if Green + Red - Blue is zero.\"}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDGSPKHHv6_8"
      },
      "source": [
        "#### calculate_savi\n",
        "Function that calculates the Soil Adjusted Vegetation Index (SAVI)\n",
        "\n",
        "$ SAVI = \\frac{(1 + L) \\cdot (NIR - Red)}{NIR + Red + L} \\in (-1.0, 1.0)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "UNjmQl6Rv-Tn",
        "outputId": "904a6e3b-96db-4adc-dbec-55de6aee23a9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def calculate_savi(band_dict):\n",
        "  \"\"\"\n",
        "  Function that calculates the Soil Adjusted Vegetation Index (SAVI) from the multispectral bands of a satellite image\n",
        "\n",
        "    parameter:  band_dict -> dictionary of multispectral band values\n",
        "    return:     savi -> Soil Adjusted Vegetation Index (SAVI) value\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "      # Extract the values for the NIR (Near Infrared) and Red bands from the dictionary\n",
        "      nir = band_dict['B5']  # Assuming 'B5' is the NIR band\n",
        "      red = band_dict['B4']  # Assuming 'B4' is the Red band\n",
        "\n",
        "      # Set the soil adjustment factor (L)\n",
        "      L = 0.5\n",
        "\n",
        "      # Calculate SAVI\n",
        "      savi = ((1 + L) * (nir - red)) / (nir + red + L)\n",
        "\n",
        "      return savi\n",
        "\n",
        "  except KeyError:\n",
        "      return {\"error\": \"Required bands (NIR and Red) not found in the band dictionary.\"}\n",
        "  except ZeroDivisionError:\n",
        "      return {\"error\": \"Division by zero error. Check if NIR + Red + L is zero.\"}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZVAIMBQwDm6"
      },
      "source": [
        "#### calculate_ndwi\n",
        "\n",
        "Function that calculates the Normalised Diffference Water Index (NDWI)\n",
        "\n",
        "$ NDWI = \\frac{Green - NIR}{Green + NIR} \\in (-1, 1)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "wNYzzUbrwKd2",
        "outputId": "590bc7ca-2ab7-483d-e6b1-50a4deb7814a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def calculate_ndwi(band_dict):\n",
        "  \"\"\"\n",
        "  Function that calculates the Normalised Diffference Water Index (NDWI) from the multispectral bands of a satellite image\n",
        "\n",
        "    parameter:  band_dict -> dictionary of multispectral band values\n",
        "    return:     ndwi -> Normalised Diffference Water Index (NDWI) value\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "      # Extract the values for the Green and NIR bands from the dictionary\n",
        "      green = band_dict['B3']  # Assuming 'B3' is the Green band\n",
        "      nir = band_dict['B5']    # Assuming 'B5' is the NIR band\n",
        "\n",
        "      # Calculate NDWI\n",
        "      ndwi = (green - nir) / (green + nir)\n",
        "\n",
        "      return ndwi\n",
        "\n",
        "  except KeyError:\n",
        "      return {\"error\": \"Required bands (Green and NIR) not found in the band dictionary.\"}\n",
        "  except ZeroDivisionError:\n",
        "      return {\"error\": \"Division by zero error. Check if Green + NIR is zero.\"}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4X_hLrCwQcD"
      },
      "source": [
        "#### calculate_evi\n",
        "\n",
        "Function that calculates the Enhanced Vegetation Index (EVI)\n",
        "\n",
        "$ EVI =  \\frac{2.5 \\cdot (NIR - Red)}{NIR + 6 \\cdot Red - 7.5 \\cdot Blue + 1} $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "uZhT5q6AwUGU",
        "outputId": "43649fc6-b42b-4932-b8fa-abb98341cf84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def calculate_evi(band_dict):\n",
        "  \"\"\"\n",
        "  Function that calculates the Enhanced Vegetation Index (EVI) from the multispectral bands of a satellite image\n",
        "\n",
        "    parameter:  band_dict -> dictionary of multispectral band values\n",
        "    return:     evi -> Enhanced Vegetation Index (EVI) value\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "      # Extract the values for the Blue, Red, and NIR bands from the dictionary\n",
        "      blue = band_dict['B2']  # Assuming 'B2' is the Blue band\n",
        "      red = band_dict['B4']   # Assuming 'B4' is the Red band\n",
        "      nir = band_dict['B5']   # Assuming 'B5' is the NIR band\n",
        "\n",
        "      # Parameters for EVI calculation\n",
        "      G = 2.5\n",
        "      C1 = 6.0\n",
        "      C2 = 7.5\n",
        "      L = 1.0  # Can be adjusted for different regions\n",
        "\n",
        "      # Calculate EVI\n",
        "      evi = G * (nir - red) / (nir + (C1 * red) - (C2 * blue) + L)\n",
        "\n",
        "      return evi\n",
        "\n",
        "  except KeyError:\n",
        "      return {\"error\": \"Required bands (Blue, Red, and NIR) not found in the band dictionary.\"}\n",
        "  except ZeroDivisionError:\n",
        "      return {\"error\": \"Division by zero error. Check if NIR + C2*Red + L is zero.\"}\n",
        "  except Exception as e:\n",
        "      return {\"error\": \"An unexpected error occurred: \" + str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8yPWOw7wYaC"
      },
      "source": [
        "### Image Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4BAySrRw8Jj"
      },
      "source": [
        "#### get_collection_landsat_image_ids\n",
        "Function that extracts a list of Landsat 8 image IDs of a co-ordinate specified location within a date range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lnSr1b2tw8ZZ",
        "outputId": "967d9555-841e-4689-af2f-42a749dcde91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_collection_landsat_image_ids(start_date, end_date, latitude, longitude):\n",
        "  \"\"\"\n",
        "  Function that extracts a list of Landsat 8 image IDs of a co-ordinate specified location within a date range\n",
        "\n",
        "    parameter:  start_date -> start date of the date range\n",
        "                end_date -> end date of the date range\n",
        "                latitude -> latitude co-ordinate of desired location\n",
        "                longitude -> longitude co-ordinate of desired location\n",
        "    return:     image_id_list -> list of Landsat 8 image IDs\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a point of interest (POI) as a geometry\n",
        "  poi = ee.Geometry.Point(longitude, latitude)\n",
        "\n",
        "  # Create an image collection for Landsat imagery\n",
        "  landsat_collection = ee.ImageCollection('LANDSAT/LC08/C01/T1_TOA') \\\n",
        "        .filterBounds(poi) \\\n",
        "        .filterDate(ee.Date.parse('YYYYMMdd', start_date), ee.Date.parse('YYYYMMdd', end_date))\n",
        "\n",
        "  # Get a list of image IDs in the collection\n",
        "  image_ids = landsat_collection.aggregate_array('system:id')\n",
        "\n",
        "  # Get the image IDs as a Python list\n",
        "  image_id_list = image_ids.getInfo()\n",
        "\n",
        "  return image_id_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u57QZ1lGw8oa"
      },
      "source": [
        "#### create_df_from_image_ids\n",
        " Function that creates a Pandas Dataframe from the Landsat 8 image collection: Image ID, Date, Co-ordinates, Band Values, Cloud Cover Percentage and Plant Indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LLLQEYWdw8y2",
        "outputId": "75ad1abf-8a08-4a4f-819d-5c47b2e3228f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def create_df_from_image_ids(image_ids, latitude, longitude):\n",
        "  \"\"\"\n",
        "  Function that creates a Pandas Dataframe from the Landsat 8 image collection: Image ID, Date, Co-ordinates, Band Values, Cloud Cover Percentage and Plant Indices.\n",
        "\n",
        "    parameter:  image_ids -> list of Landsat 8 image IDs\n",
        "                latitude -> latitude co-ordinate of desired location\n",
        "                longitude -> longitude co-ordinate of desired location\n",
        "    return:     df -> Pandas DataFrame of satellite data information for each Landsat 8 image ID\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  data = []\n",
        "\n",
        "  for image_id in image_ids:\n",
        "      # Extract date from the image ID and remove hyphens\n",
        "      date_str = image_id.split('_')[3]\n",
        "      date = ''.join(date_str.split('-'))\n",
        "\n",
        "      # Get Landsat band values for the current image\n",
        "      band_values = get_landsat_bands(image_id, latitude, longitude)\n",
        "\n",
        "      cloud = get_cloud_cover(image_id)\n",
        "\n",
        "      # Calculate Plant Indices (NDVI, EVI, SAVI, NDWI, EVI) for the current image\n",
        "      ndvi = calculate_ndvi(band_values)\n",
        "      evi = calculate_evi(band_values)\n",
        "      savi = calculate_savi(band_values)\n",
        "      ndwi = calculate_ndwi(band_values)\n",
        "      vari = calculate_vari(band_values)\n",
        "\n",
        "      # Append the data as a dictionary to the list, including band values\n",
        "      data.append({'Landsat Image ID': image_id, 'Date': date, 'Latitude': latitude, 'Longitude': longitude, **band_values, 'Cloud Cover': cloud, 'NDVI': ndvi, 'EVI': evi, 'SAVI': savi, 'VARI': vari, 'NDWI': ndwi})\n",
        "\n",
        "  # Create the Pandas DataFrame using pandas.concat\n",
        "  df = pd.concat([pd.DataFrame([d]) for d in data], ignore_index=True)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IjQsNGUuwCy"
      },
      "source": [
        "## Ameriflux Application\n",
        "\n",
        "Note: the code's commenting often refers to two attempts (where one will always be commented out and the other implemented). Attempt 1 refers to the spatially constricted 66 datasets and attempt 2 refers to the all inclusive 375 datasets. It is important that before running, each of the following cells are implementing the same attempt (i.e. all commented out or included sections agree on which attmept is being implemented)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F6Es3r6zHOh"
      },
      "source": [
        "### Ameriflux Site Overview Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "B0OPhbJAzM3g",
        "outputId": "0dece89e-c060-4670-df76-8c05cae42253"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description Filtered.csv'\n"
          ]
        }
      ],
      "source": [
        "# Ameriflux allows you to download a CSV file summarising the flux tower sites whose data you have chosen to use and their characteristics.\n",
        "#     -   the importance of this is so link the flux tower site (Site ID) with its co-ordinate point\n",
        "\n",
        "# Specify the Google Drive file path of the AmeriFlux Site Overview Dataset\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "site_overview_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description.csv'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# site_overview_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description Extended.csv'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# Load the AmeriFlux Site Overview Dataset into a Pandas DataFrame\n",
        "df_site_overview = pd.read_csv(site_overview_file_path, delimiter=';')\n",
        "\n",
        "# df_site_overview.head()                               # Uncomment to ensure proper csv file upload\n",
        "\n",
        "# Filter the AmeriFlux Site Overview Dataset\n",
        "df_site_overview['Years of AmeriFlux BASE Data'] = df_site_overview['Years of AmeriFlux BASE Data'].astype(str)                               # Converts list to string\n",
        "df_site_overview['Start Year'] = df_site_overview['Years of AmeriFlux BASE Data'].apply(lambda x: min(map(int, x.strip('()').split(','))))    # Extracts the first year from the list\n",
        "df_site_overview['End Year'] = df_site_overview['Years of AmeriFlux BASE Data'].apply(lambda x: max(map(int, x.strip('()').split(','))))      # Extracts the last year from the list\n",
        "\n",
        "# df_site_overview.head()                               # Uncomment to ensure proper start and end year extraction\n",
        "\n",
        "important_columns = ['Site ID', 'Latitude (degrees)', 'Longitude (degrees)', 'Start Year', 'End Year']    # Specifies important columns (the rest will be discarded for simplicity)\n",
        "df_site_overview_filtered = df_site_overview[important_columns]                                           # Creates a new filtered Pandad DataFrame with only the important columns\n",
        "\n",
        "# Saves the filtered AmeriFlux Site Overview Dataset the a specified Google Drive file path\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "save_df_to_drive(df_site_overview_filtered, '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description Filtered.csv')\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# save_df_to_drive(df_site_overview_filtered, '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/AmeriFlux Site Description Extended Filtered.csv')\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# df_site_overview_filtered.head()                      # Uncomment to view simplified/ filtered database containing the needed variables\n",
        "# print(df_site_overview_filtered.info())               # Uncomment to view the Pandas DataFrame's characteristics (# columns, # rows, variables, variable types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJpk4_0ruwKR"
      },
      "source": [
        "### Ameriflux Individual Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Individual Dataset Functions"
      ],
      "metadata": {
        "id": "Qfms_gxBO4E4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### get_date_range_and_coordinates\n",
        "Function that obtains the co-ordinates and operational date range of a flux tower from the AmeriFlux Site Overview dataset to be used as input parameters in extracting the landsat satellite image dataset"
      ],
      "metadata": {
        "id": "aDXXW1r7PCTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_date_range_and_coordinates(site_overview_df, file_name):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that obtains the co-ordinates and operational date range of a flux tower from the AmeriFlux Site Overview dataset\n",
        "    to be used as input parameters in extracting the landsat satellite image dataset\n",
        "\n",
        "    parameter:  site_overview_df -> overview Pandas DataFrame describing the Ameriflux flux towers and their characteristics\n",
        "                file_name -> file name of an individual Ameriflux flux tower dataset\n",
        "    return:     data_array -> array of an individual Ameriflux flux tower's characteristics (co-ordinates and date range)\n",
        "\n",
        "  \"\"\"\n",
        "  # Extract the Site ID from the flux tower dataset\n",
        "  pattern = r'AMF_(.*?)_BASE'                 # Define a regex pattern to match the desired substring - in this case the Site ID of the flux tower\n",
        "  match = re.search(pattern, file_name)       # Use re.search to find the match (i.e. the row in the overview table that refers to the name of the individual flux tower dataset)\n",
        "\n",
        "  site_id = match.group(1)\n",
        "  row_number = site_overview_df[site_overview_df['Site ID'] == site_id].index[0]      # Obtain the row number of the matched Site ID in the AmerFlux Site Overview dataset\n",
        "  longitude = site_overview_df.loc[row_number, 'Longitude (degrees)']                 # Extract the longitude from the specified row\n",
        "  latitude = site_overview_df.loc[row_number, 'Latitude (degrees)']                   # Extract the latitude from the specified row\n",
        "  start_year = site_overview_df.loc[row_number, 'Start Year']                         # Extract the start year from the specified row\n",
        "  end_year = site_overview_df.loc[row_number, 'End Year']                             # Extract the end year from the specified row\n",
        "\n",
        "  data_array = [latitude, longitude, start_year, end_year]              # Append extracted parameters to a list\n",
        "\n",
        "  return data_array"
      ],
      "metadata": {
        "id": "8X18DYK8PAwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9ff27dbb-bbae-4964-8905-37c03bca63ab"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### data_aquisition\n",
        "Function that creates and stores a filtered flux tower dataset and a generated Landsat 8 satellite dataset for each Ameriflux flux tower and saves them to specified Google Drive file paths"
      ],
      "metadata": {
        "id": "9BUk89Z7PNfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_aquisition(file_name):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that creates and stores a filtered flux tower dataset and a generated Landsat 8 satellite dataset for each Ameriflux flux tower and saves them to Google Drive folders\n",
        "\n",
        "    parameter:  file_name -> file name of an individual Ameriflux flux tower dataset\n",
        "    return:     void\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  csv_path = folder_path+\"/\"+file_name                            # Specify the Google Drive file path of the individual AmeriFlux flux tower Dataset using input paramter file_name\n",
        "  df = pd.read_csv(csv_path, delimiter=',', skiprows=2)           # Load the individual AmeriFlux flux tower Dataset into a Pandas DataFrame\n",
        "\n",
        "  # Filter the individual AmeriFlux flux tower dataset using pre-defined functions\n",
        "  df_time_seperated = timestamp_separate(df)                      # separate the timestamp variables of the Pandas DataFrame\n",
        "  df_with_LE = check_LE(df_time_seperated)                        # ensure the Pandas DataFrame has a LE column\n",
        "  df_without_LE_null_values = remove_null(df_with_LE)             # remove all null LE values from the Pandas DataFrame\n",
        "  df_grouped = group_df(df_without_LE_null_values)                # group the Pandas DataFrame by date to obtain daily entries\n",
        "\n",
        "\n",
        "  # Specify the Google Drive file path where the filtered individual AmeriFlux flux tower Dataset must be saved\n",
        "  # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "  flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered/'+file_name+' - Flux Data.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "  # flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered Extended/'+file_name+' - Flux Data Extended.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # Save the filtered individual AmeriFlux flux tower Dataset to the specified Google Drive file path\n",
        "  save_df_to_drive(df_grouped, flux_file_path)\n",
        "\n",
        "  # Generate the individual Landsat 8 satellite datasets using pre-defined functions\n",
        "  parameter_array = get_date_range_and_coordinates(df_site_overview_filtered, file_name)  # obtain the operation date range and co-ordinate specified location of the flux tower\n",
        "  latitude = parameter_array[0]                 # Extract the latitude\n",
        "  longitude = parameter_array[1]                # Extract the longitude\n",
        "  start_year = str(parameter_array[2])          # Extract the start year\n",
        "  end_year = str(parameter_array[3])            # Extract the end year\n",
        "\n",
        "  # Set the start date to the 1st of January [start year] and the end date to the 31st of December [end year]\n",
        "  start_date = start_year+'0101'\n",
        "  end_date = end_year+'1231'\n",
        "\n",
        "  # Check that the satellite can be extracted due to the operational limit of Landsat 8 satellite being post 2013\n",
        "  if int(end_year) < 2013:\n",
        "    print('Dataset cannot be extracted - outside of Landsat 8 range')\n",
        "  else:\n",
        "    landsat_ids = get_collection_landsat_image_ids(start_date, end_date, latitude, longitude)             # Create the Landsat image ID list\n",
        "\n",
        "    # This ensure code continuation in the case that the landsat_ids list is empty\n",
        "    try:\n",
        "      df_landsat = create_df_from_image_ids(landsat_ids, latitude, longitude)                             # Generate the individual Landsat 8 satellite dataset\n",
        "\n",
        "      # Specify the Google Drive file path where the filtered individual Landsat 8 satellite Dataset must be saved\n",
        "      # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "      landsat_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/First/'+file_name+' - Landsat Data.csv'\n",
        "      # -------------------------------------------------------------------------\n",
        "\n",
        "      # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "      # landsat_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/Extended/'+file_name+' - Landsat Data Extended.csv'\n",
        "      # -------------------------------------------------------------------------\n",
        "\n",
        "      # Save the individual Landsat 8 satellite Dataset to the specified Google Drive file path\n",
        "      save_df_to_drive(df_landsat, landsat_file_path)\n",
        "\n",
        "    except ValueError as ve:\n",
        "      print(f\"ValueError: {ve}\") # Handle the ValueError (No objects to concatenate)"
      ],
      "metadata": {
        "id": "exCNNXQkPN0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f3f5add2-1ad5-43d5-eee2-6730cf5e9282"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### merge_df\n",
        "Function that merges the individual filtered AmeriFlux flux tower dataset and the Landsat 8 satellite dataset for each Ameriflux flux tower and saves them to Google Drive file paths"
      ],
      "metadata": {
        "id": "q6c26274Pi1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_df(file_name):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that merges the individual filtered AmeriFlux flux tower dataset and the Landsat 8 satellite dataset for each Ameriflux flux tower and saves them to Google Drive file paths\n",
        "\n",
        "    parameter:  file_name -> file name of an individual Ameriflux flux tower dataset\n",
        "    return:     void\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Specify the Google Drive file paths where the filtered individual AmeriFlux flux tower Dataset and Landsat 8 satellite Dataset that corresponds to the input parameter file_name are stored\n",
        "  # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "  file_path_1 = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered/'+file_name+' - Flux Data.csv'\n",
        "  file_path_2 = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/First/'+file_name+' - Landsat Data.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "  # file_path_1 = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered Extended/'+file_name+' - Flux Data Extended.csv'\n",
        "  # file_path_2 = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/Extended/'+file_name+' - Landsat Data Extended.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # Load the CSV files into pandas DataFrames\n",
        "  df1 = pd.read_csv(file_path_1)                                # Pandas DataFrame that stores the individual AmeriFlux flux tower Dataset\n",
        "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)         # Pandas DataFrame that stores the individual Landsat 8 satellite Dataset\n",
        "\n",
        "  file_name = file_name.split(' - ')[0]\n",
        "\n",
        "  # Merge the Pandas DataFrames based on the common column date\n",
        "  merged_df_outer = pd.merge(df1, df2, on='Date', how='outer')\n",
        "  merged_df_inner = pd.merge(df1, df2, on='Date', how='inner')\n",
        "\n",
        "  # 'how' parameter specifies the type of merge:\n",
        "  # - 'inner': Keeps only rows with matching 'ID' in both DataFrames (default).\n",
        "  # - 'left': Keeps all rows from df1 and matching rows from df2.\n",
        "  # - 'right': Keeps all rows from df2 and matching rows from df1.\n",
        "  # - 'outer': Keeps all rows from both DataFrames.\n",
        "\n",
        "\n",
        "  # Specify the Google Drive file paths where the outer merged datasets should be saved\n",
        "  # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "  merged_outer_data_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/'+file_name+' - Outer Merged.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "  # merged_outer_data_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged Extended/'+file_name+' - Outer Merged Extended.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # Save the outer merged Dataset to the specified Google Drive file path\n",
        "  save_df_to_drive(merged_df_outer, merged_outer_data_path)\n",
        "\n",
        "\n",
        "  # Specify the Google Drive file paths where the inner merged datasets should be saved\n",
        "  # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "  merged_inner_data_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/'+file_name+' - Inner Merged.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "  # merged_inner_data_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged Extended/'+file_name+' - Inner Merged Extended.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # Save the inner merged Dataset to the specified Google Drive file path\n",
        "  save_df_to_drive(merged_df_inner, merged_inner_data_path)"
      ],
      "metadata": {
        "id": "C0TFDj8_Pjic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "69f35008-320c-40d7-ef1a-357a4f65ca64"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Individual Dataset Application"
      ],
      "metadata": {
        "id": "2CM4zbIJPwyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Extracting Original Flux Tower Datasets"
      ],
      "metadata": {
        "id": "lZpEEUv9P2yy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iuB4U9w0zf0h",
        "outputId": "d095a94e-bd06-4e8d-bdce-067a66025c0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        }
      ],
      "source": [
        "# Specify the Google Drive file path of the individual AmeriFlux Flux Tower Datasets\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Original'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Original Extended'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# Change the current working directory to the specified folder\n",
        "os.chdir(folder_path)\n",
        "\n",
        "# Create an array to store file names\n",
        "Ameriflux_datasets = []\n",
        "\n",
        "# List files in the current directory and sort them alphabetically\n",
        "file_names = sorted(os.listdir())\n",
        "\n",
        "# Append the sorted file names to the Ameriflux_datasets array\n",
        "for file_name in file_names:\n",
        "    if os.path.isfile(file_name):\n",
        "        Ameriflux_datasets.append(file_name)\n",
        "\n",
        "# SANITY CHECK: correct number of file names/ datasets\n",
        "print(len(Ameriflux_datasets))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Acquire the Filtered Flux Tower and Satellite Datasets"
      ],
      "metadata": {
        "id": "iqaXkfI-QBm0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PSvzHppKzy11",
        "outputId": "f0c7a08a-5ada-4241-e7c1-5758e7f48813"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------- AMF_US-ASH_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-ASL_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-ASM_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Bi1_BASE_HH_9-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Bi2_BASE_HH_14-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Blo_BASE_HH_4-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-CGG_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-CMW_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-DPW_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-DS3_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Dia_BASE_HH_1-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Dmg_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-EDN_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Elm_BASE_HH_4-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Esm_BASE_HH_5-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Fmf_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Fuf_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Fwf_BASE_HH_8-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Hsm_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-KS1_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-KS2_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-KS3_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-LS1_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-LS2_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Lin_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-MtB_BASE_HH_4-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Myb_BASE_HH_13-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-ONA_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-PAS_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-PSH_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-PSL_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-RGB_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-RGo_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SP1_BASE_HH_4-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SP2_BASE_HH_3-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SP3_BASE_HH_3-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SP4_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SRC_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SRG_BASE_HH_15-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SRM_BASE_HH_26-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SRS_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Snd_BASE_HH_2-1.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Sne_BASE_HH_7-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Snf_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Srr_BASE_HH_1-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SuM_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SuS_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-SuW_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Ton_BASE_HH_17-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Tw1_BASE_HH_9-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Tw2_BASE_HH_2-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Tw3_BASE_HH_5-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Tw4_BASE_HH_12-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Tw5_BASE_HH_3-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Twt_BASE_HH_7-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Var_BASE_HH_18-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Whs_BASE_HH_21-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-Wkg_BASE_HH_21-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xCL_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xDS_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xPU_BASE_HH_5-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xSB_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xSJ_BASE_HH_6-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xSP_BASE_HH_7-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xSR_BASE_HH_7-5.csv -----------------------------------\n",
            "Dataset has been extracted\n",
            "-------------------------------- AMF_US-xTE_BASE_HH_7-5.csv -----------------------------------\n",
            "Dataset has been extracted\n"
          ]
        }
      ],
      "source": [
        "# Loop through the file names in the array and apply the 'data_aquisition' function\n",
        "for file_name in Ameriflux_datasets:\n",
        "  try:\n",
        "    print(\"-------------------------------- \"+file_name+\" -----------------------------------\")\n",
        "\n",
        "    # To speed up the process of each time an error broke my code I employed this if statement to see if the file had already been aquiared\n",
        "\n",
        "    # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "    flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered/'+file_name+' - Flux Data.csv'\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "    # flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered Extended/'+file_name+' - Flux Data Extended.csv'\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    if os.path.exists(flux_file_path):\n",
        "      print('Dataset has been extracted')\n",
        "    else:\n",
        "      data_aquisition(file_name)\n",
        "\n",
        "  except KeyError as e:\n",
        "    # Handle the KeyError\n",
        "    print(f\"Error: {e} - LE column does not exist\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Merge the Filtered Flux Tower and Satellite Datasets Together"
      ],
      "metadata": {
        "id": "Vy2MhDmZQoil"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "68-dFOzPPjBN",
        "outputId": "2caca59d-35d0-49ad-a9d2-3a8be1a6956a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------- AMF_US-ASH_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-ASH_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-ASH_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-ASL_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-ASL_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-ASL_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-ASM_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-ASM_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-ASM_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Bi1_BASE_HH_9-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Bi1_BASE_HH_9-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Bi1_BASE_HH_9-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Bi2_BASE_HH_14-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Bi2_BASE_HH_14-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Bi2_BASE_HH_14-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Blo_BASE_HH_4-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-CGG_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-CGG_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-CGG_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-CMW_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-CMW_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-CMW_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-DPW_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-DPW_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-DPW_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-DS3_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-DS3_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-DS3_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Dia_BASE_HH_1-1.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Dmg_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Dmg_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Dmg_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-EDN_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-EDN_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-EDN_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Elm_BASE_HH_4-1.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Elm_BASE_HH_4-1.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Elm_BASE_HH_4-1.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Esm_BASE_HH_5-1.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Esm_BASE_HH_5-1.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Esm_BASE_HH_5-1.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Fmf_BASE_HH_6-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Fuf_BASE_HH_6-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Fwf_BASE_HH_8-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Hsm_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Hsm_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Hsm_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-KS1_BASE_HH_3-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-KS2_BASE_HH_3-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-KS3_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-KS3_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-KS3_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-LS1_BASE_HH_1-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-LS2_BASE_HH_1-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Lin_BASE_HH_2-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-MtB_BASE_HH_4-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-MtB_BASE_HH_4-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-MtB_BASE_HH_4-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Myb_BASE_HH_13-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Myb_BASE_HH_13-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Myb_BASE_HH_13-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-ONA_BASE_HH_3-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-ONA_BASE_HH_3-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-ONA_BASE_HH_3-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-PAS_BASE_HH_1-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-PSH_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-PSH_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-PSH_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-PSL_BASE_HH_1-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-RGB_BASE_HH_3-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-RGB_BASE_HH_3-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-RGB_BASE_HH_3-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-RGo_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-RGo_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-RGo_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SP1_BASE_HH_4-1.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-SP2_BASE_HH_3-1.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-SP3_BASE_HH_3-1.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-SP4_BASE_HH_3-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-SRC_BASE_HH_6-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SRC_BASE_HH_6-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SRC_BASE_HH_6-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SRG_BASE_HH_15-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SRG_BASE_HH_15-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SRG_BASE_HH_15-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SRM_BASE_HH_26-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SRM_BASE_HH_26-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SRM_BASE_HH_26-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SRS_BASE_HH_3-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SRS_BASE_HH_3-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SRS_BASE_HH_3-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Snd_BASE_HH_2-1.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Snd_BASE_HH_2-1.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Snd_BASE_HH_2-1.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Sne_BASE_HH_7-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Sne_BASE_HH_7-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Sne_BASE_HH_7-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Snf_BASE_HH_3-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Snf_BASE_HH_3-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Snf_BASE_HH_3-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Srr_BASE_HH_1-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Srr_BASE_HH_1-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Srr_BASE_HH_1-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SuM_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SuM_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SuM_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SuS_BASE_HH_2-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-SuS_BASE_HH_2-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-SuS_BASE_HH_2-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-SuW_BASE_HH_2-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Ton_BASE_HH_17-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Ton_BASE_HH_17-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Ton_BASE_HH_17-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Tw1_BASE_HH_9-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Tw1_BASE_HH_9-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Tw1_BASE_HH_9-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Tw2_BASE_HH_2-5.csv -----------------------------------\n",
            "No Satellite Date (Likely it preceeds 2013)\n",
            "-------------------------------- AMF_US-Tw3_BASE_HH_5-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Tw3_BASE_HH_5-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Tw3_BASE_HH_5-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Tw4_BASE_HH_12-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Tw4_BASE_HH_12-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Tw4_BASE_HH_12-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Tw5_BASE_HH_3-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Tw5_BASE_HH_3-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Tw5_BASE_HH_3-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Twt_BASE_HH_7-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Twt_BASE_HH_7-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Twt_BASE_HH_7-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Var_BASE_HH_18-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Var_BASE_HH_18-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Var_BASE_HH_18-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Whs_BASE_HH_21-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Whs_BASE_HH_21-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Whs_BASE_HH_21-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-Wkg_BASE_HH_21-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-Wkg_BASE_HH_21-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-Wkg_BASE_HH_21-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xCL_BASE_HH_6-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xCL_BASE_HH_6-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xCL_BASE_HH_6-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xDS_BASE_HH_6-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xDS_BASE_HH_6-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xDS_BASE_HH_6-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xPU_BASE_HH_5-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xPU_BASE_HH_5-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xPU_BASE_HH_5-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xSB_BASE_HH_6-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xSB_BASE_HH_6-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xSB_BASE_HH_6-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xSJ_BASE_HH_6-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xSJ_BASE_HH_6-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xSJ_BASE_HH_6-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xSP_BASE_HH_7-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xSP_BASE_HH_7-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xSP_BASE_HH_7-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xSR_BASE_HH_7-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xSR_BASE_HH_7-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xSR_BASE_HH_7-5.csv - Inner Merged.csv'\n",
            "-------------------------------- AMF_US-xTE_BASE_HH_7-5.csv -----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dde6c15ddb5c>:23: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(file_path_2, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Outer Merged/AMF_US-xTE_BASE_HH_7-5.csv - Outer Merged.csv'\n",
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged/AMF_US-xTE_BASE_HH_7-5.csv - Inner Merged.csv'\n"
          ]
        }
      ],
      "source": [
        "# Loop through the file names in the array and apply the 'merge_df' function\n",
        "for file_name in Ameriflux_datasets:\n",
        "  print(\"-------------------------------- \"+file_name+\" -----------------------------------\")\n",
        "\n",
        "  # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "  flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered/'+file_name+' - Flux Data.csv'\n",
        "  landsat_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/First/'+file_name+' - Landsat Data.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "  # flux_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Flux Tower Data/Ameriflux/Filtered Extended/'+file_name+' - Flux Data Extended.csv'\n",
        "  # landsat_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Satellite Data/Extended/'+file_name+' - Landsat Data Extended.csv'\n",
        "  # -------------------------------------------------------------------------\n",
        "\n",
        "  if os.path.exists(flux_file_path) and os.path.exists(landsat_file_path):\n",
        "    merge_df(file_name)\n",
        "  else:\n",
        "    print('No Satellite Date (Likely it preceeds 2013)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXail52bEXQl"
      },
      "source": [
        "##### Combine All Individual Datasets into One"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Rxt5vz4-R2-N",
        "outputId": "26893e91-0406-4877-9767-0b1f7cc4ca63"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Combined Dataset.csv'\n"
          ]
        }
      ],
      "source": [
        "# Define the path to the Google Drive folder where your CSV files are located\n",
        "\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Merged Data/Inner Merged Extended'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through the files in the folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "    # Check if the file is a CSV file\n",
        "    if file_name.endswith('.csv'):\n",
        "        # Read the CSV file into a DataFrame and append it to the list\n",
        "        df = pd.read_csv(os.path.join(folder_path, file_name))\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames in the list into one DataFrame\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# combined_df_file_path = folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Combined Dataset with error.csv' # Including error messages and missing band values\n",
        "# save_df_to_drive(combined_df, combined_df_file_path)\n",
        "\n",
        "# Specify the column where NaN values should not be considered\n",
        "column_to_exclude = 'error'  # Replace with the name of the specific column\n",
        "df_combined_and_cleaned = combined_df.dropna(subset=[col for col in df.columns if col != column_to_exclude]) # Remove rows with NaN values, except in the specified column\n",
        "\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "combined_and_cleaned_df_file_path = folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Combined Dataset.csv'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# combined_and_cleaned_df_file_path = folder_path = '/content/drive/My Drive/Colab Notebooks/Data/Combined Dataset Extended.csv'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "save_df_to_drive(df_combined_and_cleaned, combined_and_cleaned_df_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "hpehf4nl33L6",
        "outputId": "d046cea1-cb16-4819-956d-b3145bdd3d45"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1442 entries, 0 to 1506\n",
            "Data columns (total 25 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Date              1442 non-null   object \n",
            " 1   Daily LE          1442 non-null   float64\n",
            " 2   Daily Count       1442 non-null   object \n",
            " 3   Landsat Image ID  1442 non-null   object \n",
            " 4   Latitude          1442 non-null   float64\n",
            " 5   Longitude         1442 non-null   float64\n",
            " 6   B1                1442 non-null   float64\n",
            " 7   B2                1442 non-null   float64\n",
            " 8   B3                1442 non-null   float64\n",
            " 9   B4                1442 non-null   float64\n",
            " 10  B5                1442 non-null   float64\n",
            " 11  B6                1442 non-null   float64\n",
            " 12  B7                1442 non-null   float64\n",
            " 13  B8                1442 non-null   float64\n",
            " 14  B9                1442 non-null   float64\n",
            " 15  B10               1442 non-null   float64\n",
            " 16  B11               1442 non-null   float64\n",
            " 17  BQA               1442 non-null   float64\n",
            " 18  Cloud Cover       1442 non-null   float64\n",
            " 19  NDVI              1442 non-null   object \n",
            " 20  EVI               1442 non-null   object \n",
            " 21  SAVI              1442 non-null   object \n",
            " 22  VARI              1442 non-null   object \n",
            " 23  NDWI              1442 non-null   object \n",
            " 24  error             0 non-null      object \n",
            "dtypes: float64(16), object(9)\n",
            "memory usage: 292.9+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Date     Daily LE Daily Count  \\\n",
              "0  20161019  3743.284896        2304   \n",
              "1  20161026  3511.882929        2304   \n",
              "2  20161104  2136.691500        2304   \n",
              "3  20161111  2517.055224        2304   \n",
              "4  20161127  2055.056845        2304   \n",
              "\n",
              "                               Landsat Image ID  Latitude  Longitude  \\\n",
              "0  LANDSAT/LC08/C01/T1_TOA/LC08_042035_20161019   36.1697   -120.201   \n",
              "1  LANDSAT/LC08/C01/T1_TOA/LC08_043035_20161026   36.1697   -120.201   \n",
              "2  LANDSAT/LC08/C01/T1_TOA/LC08_042035_20161104   36.1697   -120.201   \n",
              "3  LANDSAT/LC08/C01/T1_TOA/LC08_043035_20161111   36.1697   -120.201   \n",
              "4  LANDSAT/LC08/C01/T1_TOA/LC08_043035_20161127   36.1697   -120.201   \n",
              "\n",
              "         B1        B2        B3        B4  ...         B10         B11  \\\n",
              "0  0.129312  0.107969  0.094198  0.080152  ...  294.060547  292.998322   \n",
              "1  0.125262  0.104519  0.090530  0.077565  ...  296.055389  294.163574   \n",
              "2  0.170604  0.147830  0.132317  0.113736  ...  284.938782  283.150085   \n",
              "3  0.153352  0.127818  0.108407  0.090966  ...  289.738831  288.493958   \n",
              "4  0.129083  0.102393  0.081025  0.059895  ...  284.973633  284.453094   \n",
              "\n",
              "      BQA  Cloud Cover      NDVI       EVI      SAVI      VARI      NDWI error  \n",
              "0  2720.0         0.15  0.524457  0.476226  0.316796  0.211592 -0.463478   NaN  \n",
              "1  2720.0         4.15  0.515012  0.445805  0.301392  0.203928 -0.455997   NaN  \n",
              "2  6816.0        11.01  0.467943  0.563557  0.323537   0.18917 -0.406802   NaN  \n",
              "3  2720.0        35.87   0.47281  0.484864  0.289609  0.243744 -0.401956   NaN  \n",
              "4  2720.0        29.63  0.582329  0.510228  0.318404  0.548454 -0.473752   NaN  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b52d1824-235f-48ea-bf02-687750e2142d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Daily LE</th>\n",
              "      <th>Daily Count</th>\n",
              "      <th>Landsat Image ID</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>...</th>\n",
              "      <th>B10</th>\n",
              "      <th>B11</th>\n",
              "      <th>BQA</th>\n",
              "      <th>Cloud Cover</th>\n",
              "      <th>NDVI</th>\n",
              "      <th>EVI</th>\n",
              "      <th>SAVI</th>\n",
              "      <th>VARI</th>\n",
              "      <th>NDWI</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20161019</td>\n",
              "      <td>3743.284896</td>\n",
              "      <td>2304</td>\n",
              "      <td>LANDSAT/LC08/C01/T1_TOA/LC08_042035_20161019</td>\n",
              "      <td>36.1697</td>\n",
              "      <td>-120.201</td>\n",
              "      <td>0.129312</td>\n",
              "      <td>0.107969</td>\n",
              "      <td>0.094198</td>\n",
              "      <td>0.080152</td>\n",
              "      <td>...</td>\n",
              "      <td>294.060547</td>\n",
              "      <td>292.998322</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.524457</td>\n",
              "      <td>0.476226</td>\n",
              "      <td>0.316796</td>\n",
              "      <td>0.211592</td>\n",
              "      <td>-0.463478</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20161026</td>\n",
              "      <td>3511.882929</td>\n",
              "      <td>2304</td>\n",
              "      <td>LANDSAT/LC08/C01/T1_TOA/LC08_043035_20161026</td>\n",
              "      <td>36.1697</td>\n",
              "      <td>-120.201</td>\n",
              "      <td>0.125262</td>\n",
              "      <td>0.104519</td>\n",
              "      <td>0.090530</td>\n",
              "      <td>0.077565</td>\n",
              "      <td>...</td>\n",
              "      <td>296.055389</td>\n",
              "      <td>294.163574</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>4.15</td>\n",
              "      <td>0.515012</td>\n",
              "      <td>0.445805</td>\n",
              "      <td>0.301392</td>\n",
              "      <td>0.203928</td>\n",
              "      <td>-0.455997</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20161104</td>\n",
              "      <td>2136.691500</td>\n",
              "      <td>2304</td>\n",
              "      <td>LANDSAT/LC08/C01/T1_TOA/LC08_042035_20161104</td>\n",
              "      <td>36.1697</td>\n",
              "      <td>-120.201</td>\n",
              "      <td>0.170604</td>\n",
              "      <td>0.147830</td>\n",
              "      <td>0.132317</td>\n",
              "      <td>0.113736</td>\n",
              "      <td>...</td>\n",
              "      <td>284.938782</td>\n",
              "      <td>283.150085</td>\n",
              "      <td>6816.0</td>\n",
              "      <td>11.01</td>\n",
              "      <td>0.467943</td>\n",
              "      <td>0.563557</td>\n",
              "      <td>0.323537</td>\n",
              "      <td>0.18917</td>\n",
              "      <td>-0.406802</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20161111</td>\n",
              "      <td>2517.055224</td>\n",
              "      <td>2304</td>\n",
              "      <td>LANDSAT/LC08/C01/T1_TOA/LC08_043035_20161111</td>\n",
              "      <td>36.1697</td>\n",
              "      <td>-120.201</td>\n",
              "      <td>0.153352</td>\n",
              "      <td>0.127818</td>\n",
              "      <td>0.108407</td>\n",
              "      <td>0.090966</td>\n",
              "      <td>...</td>\n",
              "      <td>289.738831</td>\n",
              "      <td>288.493958</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>35.87</td>\n",
              "      <td>0.47281</td>\n",
              "      <td>0.484864</td>\n",
              "      <td>0.289609</td>\n",
              "      <td>0.243744</td>\n",
              "      <td>-0.401956</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20161127</td>\n",
              "      <td>2055.056845</td>\n",
              "      <td>2304</td>\n",
              "      <td>LANDSAT/LC08/C01/T1_TOA/LC08_043035_20161127</td>\n",
              "      <td>36.1697</td>\n",
              "      <td>-120.201</td>\n",
              "      <td>0.129083</td>\n",
              "      <td>0.102393</td>\n",
              "      <td>0.081025</td>\n",
              "      <td>0.059895</td>\n",
              "      <td>...</td>\n",
              "      <td>284.973633</td>\n",
              "      <td>284.453094</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>29.63</td>\n",
              "      <td>0.582329</td>\n",
              "      <td>0.510228</td>\n",
              "      <td>0.318404</td>\n",
              "      <td>0.548454</td>\n",
              "      <td>-0.473752</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b52d1824-235f-48ea-bf02-687750e2142d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b52d1824-235f-48ea-bf02-687750e2142d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b52d1824-235f-48ea-bf02-687750e2142d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd1d0ace-45e3-421e-9d8d-b22a0ad8769b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd1d0ace-45e3-421e-9d8d-b22a0ad8769b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd1d0ace-45e3-421e-9d8d-b22a0ad8769b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# SANITY CHECK: check number of columns and rows, variables and their data types\n",
        "print(df_combined_and_cleaned.info())\n",
        "df_combined_and_cleaned.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Process the Single Dataset for Machine Learning Application"
      ],
      "metadata": {
        "id": "owMiSbbcRCi2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "iL8ITyVu7kmg",
        "outputId": "3efcfa91-d4c6-4d15-85e9-1c04261aa009"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date).csv'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Daily LE      Date        B1        B2        B3        B4        B5  \\\n",
              "0  3743.284896  20161019  0.129312  0.107969  0.094198  0.080152  0.256945   \n",
              "1  3511.882929  20161026  0.125262  0.104519  0.090530  0.077565  0.242298   \n",
              "2  2136.691500  20161104  0.170604  0.147830  0.132317  0.113736  0.313797   \n",
              "3  2517.055224  20161111  0.153352  0.127818  0.108407  0.090966  0.254131   \n",
              "4  2055.056845  20161127  0.129083  0.102393  0.081025  0.059895  0.226909   \n",
              "\n",
              "         B6        B7        B8        B9         B10         B11     BQA  \\\n",
              "0  0.156945  0.087725  0.090320  0.001130  294.060547  292.998322  2720.0   \n",
              "1  0.150072  0.084479  0.084928  0.001056  296.055389  294.163574  2720.0   \n",
              "2  0.187037  0.115338  0.123078  0.030207  284.938782  283.150085  6816.0   \n",
              "3  0.143038  0.080938  0.100026  0.012391  289.738831  288.493958  2720.0   \n",
              "4  0.106365  0.049330  0.071254  0.001072  284.973633  284.453094  2720.0   \n",
              "\n",
              "   Cloud Cover      NDVI       EVI      SAVI      VARI      NDWI  \n",
              "0         0.15  0.524457  0.476226  0.316796  0.211592 -0.463478  \n",
              "1         4.15  0.515012  0.445805  0.301392  0.203928 -0.455997  \n",
              "2        11.01  0.467943  0.563557  0.323537   0.18917 -0.406802  \n",
              "3        35.87   0.47281  0.484864  0.289609  0.243744 -0.401956  \n",
              "4        29.63  0.582329  0.510228  0.318404  0.548454 -0.473752  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6dd4a95-a7e7-41b1-9cc7-9b6a4fe55fd8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Daily LE</th>\n",
              "      <th>Date</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B5</th>\n",
              "      <th>B6</th>\n",
              "      <th>B7</th>\n",
              "      <th>B8</th>\n",
              "      <th>B9</th>\n",
              "      <th>B10</th>\n",
              "      <th>B11</th>\n",
              "      <th>BQA</th>\n",
              "      <th>Cloud Cover</th>\n",
              "      <th>NDVI</th>\n",
              "      <th>EVI</th>\n",
              "      <th>SAVI</th>\n",
              "      <th>VARI</th>\n",
              "      <th>NDWI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3743.284896</td>\n",
              "      <td>20161019</td>\n",
              "      <td>0.129312</td>\n",
              "      <td>0.107969</td>\n",
              "      <td>0.094198</td>\n",
              "      <td>0.080152</td>\n",
              "      <td>0.256945</td>\n",
              "      <td>0.156945</td>\n",
              "      <td>0.087725</td>\n",
              "      <td>0.090320</td>\n",
              "      <td>0.001130</td>\n",
              "      <td>294.060547</td>\n",
              "      <td>292.998322</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.524457</td>\n",
              "      <td>0.476226</td>\n",
              "      <td>0.316796</td>\n",
              "      <td>0.211592</td>\n",
              "      <td>-0.463478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3511.882929</td>\n",
              "      <td>20161026</td>\n",
              "      <td>0.125262</td>\n",
              "      <td>0.104519</td>\n",
              "      <td>0.090530</td>\n",
              "      <td>0.077565</td>\n",
              "      <td>0.242298</td>\n",
              "      <td>0.150072</td>\n",
              "      <td>0.084479</td>\n",
              "      <td>0.084928</td>\n",
              "      <td>0.001056</td>\n",
              "      <td>296.055389</td>\n",
              "      <td>294.163574</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>4.15</td>\n",
              "      <td>0.515012</td>\n",
              "      <td>0.445805</td>\n",
              "      <td>0.301392</td>\n",
              "      <td>0.203928</td>\n",
              "      <td>-0.455997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2136.691500</td>\n",
              "      <td>20161104</td>\n",
              "      <td>0.170604</td>\n",
              "      <td>0.147830</td>\n",
              "      <td>0.132317</td>\n",
              "      <td>0.113736</td>\n",
              "      <td>0.313797</td>\n",
              "      <td>0.187037</td>\n",
              "      <td>0.115338</td>\n",
              "      <td>0.123078</td>\n",
              "      <td>0.030207</td>\n",
              "      <td>284.938782</td>\n",
              "      <td>283.150085</td>\n",
              "      <td>6816.0</td>\n",
              "      <td>11.01</td>\n",
              "      <td>0.467943</td>\n",
              "      <td>0.563557</td>\n",
              "      <td>0.323537</td>\n",
              "      <td>0.18917</td>\n",
              "      <td>-0.406802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2517.055224</td>\n",
              "      <td>20161111</td>\n",
              "      <td>0.153352</td>\n",
              "      <td>0.127818</td>\n",
              "      <td>0.108407</td>\n",
              "      <td>0.090966</td>\n",
              "      <td>0.254131</td>\n",
              "      <td>0.143038</td>\n",
              "      <td>0.080938</td>\n",
              "      <td>0.100026</td>\n",
              "      <td>0.012391</td>\n",
              "      <td>289.738831</td>\n",
              "      <td>288.493958</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>35.87</td>\n",
              "      <td>0.47281</td>\n",
              "      <td>0.484864</td>\n",
              "      <td>0.289609</td>\n",
              "      <td>0.243744</td>\n",
              "      <td>-0.401956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2055.056845</td>\n",
              "      <td>20161127</td>\n",
              "      <td>0.129083</td>\n",
              "      <td>0.102393</td>\n",
              "      <td>0.081025</td>\n",
              "      <td>0.059895</td>\n",
              "      <td>0.226909</td>\n",
              "      <td>0.106365</td>\n",
              "      <td>0.049330</td>\n",
              "      <td>0.071254</td>\n",
              "      <td>0.001072</td>\n",
              "      <td>284.973633</td>\n",
              "      <td>284.453094</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>29.63</td>\n",
              "      <td>0.582329</td>\n",
              "      <td>0.510228</td>\n",
              "      <td>0.318404</td>\n",
              "      <td>0.548454</td>\n",
              "      <td>-0.473752</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6dd4a95-a7e7-41b1-9cc7-9b6a4fe55fd8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6dd4a95-a7e7-41b1-9cc7-9b6a4fe55fd8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6dd4a95-a7e7-41b1-9cc7-9b6a4fe55fd8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb6665a9-e9d0-4c2c-b357-60cee7cb5d28\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb6665a9-e9d0-4c2c-b357-60cee7cb5d28')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb6665a9-e9d0-4c2c-b357-60cee7cb5d28 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Extract only the neccesary variables for machine learning model dataset\n",
        "\n",
        "## ------------------------------------------------------------------------ Without Date ------------------------------------------------------------------------\n",
        "# ml_columns = ['Daily LE', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'BQA', 'Cloud Cover', 'NDVI', 'EVI', 'SAVI', 'VARI', 'NDWI']\n",
        "# ml_df = df_combined_and_cleaned[ml_columns]\n",
        "\n",
        "# # ------------------------------- ATTEMPT 1 -------------------------------\n",
        "# # ml_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset.csv'\n",
        "# # -------------------------------------------------------------------------\n",
        "\n",
        "# # ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# ml_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset Extended.csv'\n",
        "# # -------------------------------------------------------------------------\n",
        "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# -------------------------------------------------------------------------- With Date --------------------------------------------------------------------------\n",
        "ml_columns = ['Daily LE', 'Date', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'BQA', 'Cloud Cover', 'NDVI', 'EVI', 'SAVI', 'VARI', 'NDWI']\n",
        "ml_df = df_combined_and_cleaned[ml_columns]\n",
        "\n",
        "# ------------------------------- ATTEMPT 1 -------------------------------\n",
        "ml_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date).csv'\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------- ATTEMPT 2 -------------------------------\n",
        "# ml_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset Extended (Date).csv'\n",
        "# -------------------------------------------------------------------------\n",
        "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "save_df_to_drive(ml_df, ml_file_path)\n",
        "\n",
        "ml_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Date Variable Variation"
      ],
      "metadata": {
        "id": "Y3dgARxrRhp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# until this point the dat variable as being 'fed' into the machine learning (ML) model as a string\n",
        "  # this is an investigation as to whether the perfromance could be improved if it was a different data type\n",
        "\n",
        "df_epoch = ml_df\n",
        "\n",
        "# Date was converted to Epoch (numeric representation)\n",
        "df_epoch['Date'] = pd.to_datetime(df_epoch['Date'], format='%Y%m%d')\n",
        "df_epoch['Date Epoch'] = df_epoch['Date'].astype(int) // 10**9  # Convert to seconds since epoch\n",
        "df_epoch = df_epoch.drop('Date', axis=1)\n",
        "\n",
        "df_epoch_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date) - epoch.csv'\n",
        "save_df_to_drive(df_epoch, df_epoch_file_path)\n",
        "\n",
        "# Date was converted to Epoch (numeric representation) and the day, month and year of the dat were included\n",
        "df_epoch_and = ml_df\n",
        "df_epoch_and['Year'] = df_epoch_and['Date'].dt.year\n",
        "df_epoch_and['Month'] = df_epoch_and['Date'].dt.month\n",
        "df_epoch_and['Day'] = df_epoch_and['Date'].dt.day\n",
        "df_epoch_and = df_epoch_and.drop('Date', axis=1)\n",
        "\n",
        "df_epoch_and_file_path = '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date) - epoch, year, month, day.csv'\n",
        "save_df_to_drive(df_epoch_and, df_epoch_and_file_path)\n",
        "\n",
        "df_epoch.head()\n",
        "df_epoch_and.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "DiDQDqHo1wzv",
        "outputId": "37293a2a-177e-4180-ae3d-2853f4f67127"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-22521c8de0be>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_epoch['Date'] = pd.to_datetime(df_epoch['Date'], format='%Y%m%d')\n",
            "<ipython-input-26-22521c8de0be>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_epoch['Date Epoch'] = df_epoch['Date'].astype(int) // 10**9  # Convert to seconds since epoch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date) - epoch.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-22521c8de0be>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_epoch_and['Year'] = df_epoch_and['Date'].dt.year\n",
            "<ipython-input-26-22521c8de0be>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_epoch_and['Month'] = df_epoch_and['Date'].dt.month\n",
            "<ipython-input-26-22521c8de0be>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_epoch_and['Day'] = df_epoch_and['Date'].dt.day\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to Google Drive at '/content/drive/My Drive/Colab Notebooks/Data/Machine Learning Dataset (Date) - epoch, year, month, day.csv'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Daily LE        B1        B2        B3        B4        B5        B6  \\\n",
              "0  3743.284896  0.129312  0.107969  0.094198  0.080152  0.256945  0.156945   \n",
              "1  3511.882929  0.125262  0.104519  0.090530  0.077565  0.242298  0.150072   \n",
              "2  2136.691500  0.170604  0.147830  0.132317  0.113736  0.313797  0.187037   \n",
              "3  2517.055224  0.153352  0.127818  0.108407  0.090966  0.254131  0.143038   \n",
              "4  2055.056845  0.129083  0.102393  0.081025  0.059895  0.226909  0.106365   \n",
              "\n",
              "         B7        B8        B9  ...  Cloud Cover      NDVI       EVI  \\\n",
              "0  0.087725  0.090320  0.001130  ...         0.15  0.524457  0.476226   \n",
              "1  0.084479  0.084928  0.001056  ...         4.15  0.515012  0.445805   \n",
              "2  0.115338  0.123078  0.030207  ...        11.01  0.467943  0.563557   \n",
              "3  0.080938  0.100026  0.012391  ...        35.87   0.47281  0.484864   \n",
              "4  0.049330  0.071254  0.001072  ...        29.63  0.582329  0.510228   \n",
              "\n",
              "       SAVI      VARI      NDWI  Date Epoch  Year Month  Day  \n",
              "0  0.316796  0.211592 -0.463478  1476835200  2016    10   19  \n",
              "1  0.301392  0.203928 -0.455997  1477440000  2016    10   26  \n",
              "2  0.323537   0.18917 -0.406802  1478217600  2016    11    4  \n",
              "3  0.289609  0.243744 -0.401956  1478822400  2016    11   11  \n",
              "4  0.318404  0.548454 -0.473752  1480204800  2016    11   27  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7d697b3-67e0-4511-9f6d-d40a6d0eeda6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Daily LE</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B5</th>\n",
              "      <th>B6</th>\n",
              "      <th>B7</th>\n",
              "      <th>B8</th>\n",
              "      <th>B9</th>\n",
              "      <th>...</th>\n",
              "      <th>Cloud Cover</th>\n",
              "      <th>NDVI</th>\n",
              "      <th>EVI</th>\n",
              "      <th>SAVI</th>\n",
              "      <th>VARI</th>\n",
              "      <th>NDWI</th>\n",
              "      <th>Date Epoch</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3743.284896</td>\n",
              "      <td>0.129312</td>\n",
              "      <td>0.107969</td>\n",
              "      <td>0.094198</td>\n",
              "      <td>0.080152</td>\n",
              "      <td>0.256945</td>\n",
              "      <td>0.156945</td>\n",
              "      <td>0.087725</td>\n",
              "      <td>0.090320</td>\n",
              "      <td>0.001130</td>\n",
              "      <td>...</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.524457</td>\n",
              "      <td>0.476226</td>\n",
              "      <td>0.316796</td>\n",
              "      <td>0.211592</td>\n",
              "      <td>-0.463478</td>\n",
              "      <td>1476835200</td>\n",
              "      <td>2016</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3511.882929</td>\n",
              "      <td>0.125262</td>\n",
              "      <td>0.104519</td>\n",
              "      <td>0.090530</td>\n",
              "      <td>0.077565</td>\n",
              "      <td>0.242298</td>\n",
              "      <td>0.150072</td>\n",
              "      <td>0.084479</td>\n",
              "      <td>0.084928</td>\n",
              "      <td>0.001056</td>\n",
              "      <td>...</td>\n",
              "      <td>4.15</td>\n",
              "      <td>0.515012</td>\n",
              "      <td>0.445805</td>\n",
              "      <td>0.301392</td>\n",
              "      <td>0.203928</td>\n",
              "      <td>-0.455997</td>\n",
              "      <td>1477440000</td>\n",
              "      <td>2016</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2136.691500</td>\n",
              "      <td>0.170604</td>\n",
              "      <td>0.147830</td>\n",
              "      <td>0.132317</td>\n",
              "      <td>0.113736</td>\n",
              "      <td>0.313797</td>\n",
              "      <td>0.187037</td>\n",
              "      <td>0.115338</td>\n",
              "      <td>0.123078</td>\n",
              "      <td>0.030207</td>\n",
              "      <td>...</td>\n",
              "      <td>11.01</td>\n",
              "      <td>0.467943</td>\n",
              "      <td>0.563557</td>\n",
              "      <td>0.323537</td>\n",
              "      <td>0.18917</td>\n",
              "      <td>-0.406802</td>\n",
              "      <td>1478217600</td>\n",
              "      <td>2016</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2517.055224</td>\n",
              "      <td>0.153352</td>\n",
              "      <td>0.127818</td>\n",
              "      <td>0.108407</td>\n",
              "      <td>0.090966</td>\n",
              "      <td>0.254131</td>\n",
              "      <td>0.143038</td>\n",
              "      <td>0.080938</td>\n",
              "      <td>0.100026</td>\n",
              "      <td>0.012391</td>\n",
              "      <td>...</td>\n",
              "      <td>35.87</td>\n",
              "      <td>0.47281</td>\n",
              "      <td>0.484864</td>\n",
              "      <td>0.289609</td>\n",
              "      <td>0.243744</td>\n",
              "      <td>-0.401956</td>\n",
              "      <td>1478822400</td>\n",
              "      <td>2016</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2055.056845</td>\n",
              "      <td>0.129083</td>\n",
              "      <td>0.102393</td>\n",
              "      <td>0.081025</td>\n",
              "      <td>0.059895</td>\n",
              "      <td>0.226909</td>\n",
              "      <td>0.106365</td>\n",
              "      <td>0.049330</td>\n",
              "      <td>0.071254</td>\n",
              "      <td>0.001072</td>\n",
              "      <td>...</td>\n",
              "      <td>29.63</td>\n",
              "      <td>0.582329</td>\n",
              "      <td>0.510228</td>\n",
              "      <td>0.318404</td>\n",
              "      <td>0.548454</td>\n",
              "      <td>-0.473752</td>\n",
              "      <td>1480204800</td>\n",
              "      <td>2016</td>\n",
              "      <td>11</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7d697b3-67e0-4511-9f6d-d40a6d0eeda6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b7d697b3-67e0-4511-9f6d-d40a6d0eeda6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b7d697b3-67e0-4511-9f6d-d40a6d0eeda6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-30efd65e-6495-4b44-8ece-8ea825edad6e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30efd65e-6495-4b44-8ece-8ea825edad6e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-30efd65e-6495-4b44-8ece-8ea825edad6e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "GDwY-VJ1tbkG",
        "0Ofb6MgatwJt",
        "cFpAcbzvt-GT",
        "T9EPLy1luvNU",
        "6gjANH7hyJiR",
        "PLoKcu4H6ihS",
        "TE0HGzsfyaPi",
        "qNG6_T7uyjfO",
        "7Cju7kPvyUGd",
        "dOa3asdjuvgl",
        "_Sg9DvmEuvsh",
        "AW7zVy6qvXFe",
        "SDxovsU2vg_7",
        "vOQ7ctGsvsuM",
        "rDGSPKHHv6_8",
        "PZVAIMBQwDm6",
        "I4X_hLrCwQcD",
        "H8yPWOw7wYaC",
        "r4BAySrRw8Jj",
        "u57QZ1lGw8oa",
        "9F6Es3r6zHOh",
        "Qfms_gxBO4E4",
        "aDXXW1r7PCTA",
        "9BUk89Z7PNfF",
        "q6c26274Pi1l",
        "iqaXkfI-QBm0",
        "Vy2MhDmZQoil",
        "gXail52bEXQl",
        "owMiSbbcRCi2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}